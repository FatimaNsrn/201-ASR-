{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1eIkItT6B4Zi",
    "outputId": "1f564cb3-4bc0-4ff5-ffc8-5eb4a2e3fe03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jiwer\n",
      "  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from jiwer) (8.3.1)\n",
      "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
      "  Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
      "Downloading jiwer-4.0.0-py3-none-any.whl (23 kB)\n",
      "Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
      "Successfully installed jiwer-4.0.0 rapidfuzz-3.14.3\n"
     ]
    }
   ],
   "source": [
    "# %pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LpcJ2GGRCY3V",
    "outputId": "96a3562d-65ab-4a26-b737-b049ffd0f278"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchcodec in /usr/local/lib/python3.12/dist-packages (0.9.1)\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade torchcodec\n",
    "#Note : It is quite hard to run the code so please execute the commands  one by one because of dependencies issues. \n",
    "#Also maybe it will tell you to restart the runtime so idk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8cf25df5",
    "outputId": "fe8420f6-5e37-453b-e06d-954766109842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow, datasets\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 18.1.0\n",
      "    Uninstalling pyarrow-18.1.0:\n",
      "      Successfully uninstalled pyarrow-18.1.0\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 4.0.0\n",
      "    Uninstalling datasets-4.0.0:\n",
      "      Successfully uninstalled datasets-4.0.0\n",
      "Successfully installed datasets-4.4.1 pyarrow-22.0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "364662fa543b41d192a44bf8a2cc4534",
       "pip_warning": {
        "packages": [
         "datasets",
         "pyarrow"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install --upgrade datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b40290352cc847628c6b9717d41291b7",
      "853c7918eb0149e19f6da98246ed94b3",
      "71c1fb132a2b42d8b37f0dc1e373192d",
      "9457eab8d50943d3876cd2c7fd43b6bc",
      "c6e6f690c6534c8e905b4e88f4f52e00",
      "877e18d3f3884b5a8a3bae0b865b6047",
      "67d7f4a812684a2fbef77f4dc0945ea7",
      "9ad5fdc236fa40a1bde173f475870146",
      "dc67b8e101b543a4a0da30345935663c",
      "ea16f0ad6b2e406db3d92cdfab63e860",
      "bafa0db0a08f44f4bdaa5a803f02085d",
      "93e3f2ccd43041d084a44cc385d65401",
      "4aa5909e612f4077a6bfd0f5d3309812",
      "7db36fcfe7e0462aa6e28b5d4ab7b91a",
      "bd270b1439cf40e6a6c81c6094549e3c",
      "ee3e2f814bb0486d80a830e437e723a3",
      "67efa89537e74fdc8c322dab1050a24a",
      "942c9920651944e7804e14b610b339a5",
      "1e753c9f94b5473ea26cd8179f49f603",
      "bc444f1497a64b6a8a0b44a4307d5197",
      "f8f440e9bc4c445fbded7422170d7afa",
      "b46d70b2e5734ca48be0451d2a86c56a",
      "3c70d9702d294a73a154de265a0fde67",
      "824fbdc426a54b6dac9b18bb99b43ce6",
      "615ac1592016406eafebe183518f8298",
      "97b1cd77a2c84fa389ff3f28f0e905c8",
      "f452ef9da0f14f91b06c722b9031b2a2",
      "f9a6998c9ca04c35a6333f83676f65c4",
      "fef4e508efc84cf193cc1f1f01ae8c86",
      "237099586a6849b9b081798b5516be28",
      "5e48e4dc4f794bc987d9d55ebbb182f2",
      "bfd2c905035d4a67bd5b935a35f76510",
      "70a950a6aaae4455baa72dc54f05bd8d",
      "aad47a9df3c4492d8f99a88587fe0e39",
      "1b2ddd31cb2e4c2da231713a3be47766",
      "5b6de49c63e84c089fc0151c03337011",
      "6ee259944f9f464e8e970b270eca9b5e",
      "d0aa4ce7abc34f3b9a673fd39cf0781e",
      "798c928ac84d44ea85d6c3ec62dc313a",
      "928d04c9f68b4c188c135aa1c411c873",
      "0420de646b264a8e8ce051ae90979e09",
      "6a4a1b7a1d32430a9ade29a4fe7f1ffb",
      "62443bb183cd4f35a1acffac95c47d21",
      "115acbc278474716822884eafbe1c4a3",
      "8bdf44a88c9c4336abdd368600a9398c",
      "22cb9d62266244979b40ab9f2c88323d",
      "45417057ff4a4d4a9a59ef6f3618bb21",
      "95b42601eccb4da7a8918abaa2841f0d",
      "522c61683f00416483f4fec70340b3c1",
      "7228030f06c7464d90bba879e0570878",
      "705ef2fa403441fb9cb3febe859e9ddc",
      "d270328cb4474b68aa60529a68bac59b",
      "5eb8ffc5c8b045c4acec18c98d9c9782",
      "f95a6670af77449a8bd59f814cf68555",
      "ad23fcfd99d64359891b4403eeca305c",
      "f04f5263132e412f8c7d1eb89a9a0da4",
      "42a70c1698c14803b362745e2c248686",
      "131cec9ec12443b5bb7507e90b2f43c6",
      "ce4dcc75b9ba40a1b727eb55065fe9ff",
      "45d8eb4bc6b94c1eb559785535a6e5f9",
      "e77f7b84e5644d98909f0188cfc29da6",
      "159e97f5d50e47bc836d913e5661f29d",
      "36ea7764f1a6433c84133aa81c19973c",
      "4836778879ec41df8c51df99c84d30e7",
      "9d9d91c17f244722b2bcb74895208638",
      "5ad2690ee750476e972b2a0221032f37",
      "c48e0c35313c45c8b16357da6feee6e0",
      "65547f2073c9456bbd2df620bd5ba02f",
      "1c5725c98656454db51ce72537ed1b15",
      "bb5b85298ada44a28dc76df1a3335148",
      "889cf39dac654dbb8544d10689abd540",
      "b969344154b14fd7b3734b16052bec2d",
      "d9e864cd41af440da583c464276e21ec",
      "7287e23e762a4e0f8e2ff5e858edff39",
      "2c20dc6824a14d99a9471a492fb05130",
      "bdaf47edd88040afa583cb8790625fd4",
      "ae2ce9b05c484d5c8f2b686ae290dfc8",
      "563719ee20c44e9b807beb2062b8262c",
      "220f43f326634e748c1fd4eb7844ea13",
      "02368b5ca83c4341bb59a2278120ccad",
      "0b2c3840483a41e883f3708457634bba",
      "265d6ba4b0654265bf8828e8417ac855",
      "46b3a926f13440959847cb3541e5d2be",
      "9ea0123e93f94f4f9654ad5587324ec5",
      "4b29ec62f5aa46b388116b045810fad6",
      "f819b0550aa14e3893900c676e527f5a",
      "79a66bb2712b47ff94a4a1185111f50d",
      "911530e16df84d60924c2e2910eeee30",
      "27f3f0a3f76f4ab9bbd53c138a1fb272",
      "cb8026446af545c0b1789a8b328f78f6",
      "63acc0470fa240ae8469f51f15b78e88",
      "fee85d6a2a644ca6b4c42dfef1b89a5c",
      "97e192972ba64e078060ed07fd83d2d0",
      "0eb8ffe895e143fb846ad854a4cfbf5d",
      "30a7f71433bd45c3908672f0319de18e",
      "3dc8b640995c4c409fd054801ca80ff7",
      "96a08cedfdf74831949a4dfc7c64f89c",
      "96c4db3e1e2749549531aacaf0177180",
      "697e8ec2dc264024842fa8e2cce39980",
      "a01d57b0792e4837a4a7d348bba67309",
      "c374dc401ac64a7b9ef74f661263ac08",
      "1522150b9474492296dbdf3c7844ec6d",
      "a2a693e9727848759e5eb0c305928ef5",
      "526e05db5bb14c64b25987b176a55d52",
      "c7037d1559164c0aa1e4655832a75fa6",
      "b5de440a4ef14dcab6616a0e01ca5afc",
      "83daabec4d0744a09ff325424a90d85f",
      "b77bd5e787144c488c3319923345c364",
      "5ae82e505eb146cc9263e391e5a50e97",
      "20ca6f76a36e4bbbbb3567a70fcef434",
      "521c236728de40d08bbd0db2c6bec927",
      "cf35b4ede1f246dd81db3b7fc7a8b822",
      "515b6680cb0d495cacb14ec918600dae",
      "9db529da6abd4985b8e13e341b6e0fbe",
      "ff60dff3e8fc4c3c98bdd82360e80e30",
      "89982337d38c4bc7a0e667f873a94965",
      "324b8208cdd946129df297bab472431c",
      "bf313b4f59a04e539ef7915d507b9cc3",
      "daf280152826433fb7228d37a530f260",
      "bc7bd65be6794085bb981b478e772eda",
      "9ee70e32891a49c8886b616a0c2ef11a",
      "ae06e03540124a62b76cd60c04dcd3e4",
      "f863b1aee7cc47b98fb2fe4507da029f",
      "42d3592750e341c0946fcc71e359ceb4",
      "591632acec5445339082faf00a5201c1",
      "4af8324b189b492bb96f1d0916da44a5",
      "b3e0f2c00d7c48b997f83a7f9c201db1",
      "e8c3934d327149c3a23b9815d9752a70",
      "569dd40b1e5f4521b8c5b3fa334eae01",
      "82172d30a78442b19fe6122b06897544",
      "4d02ded5fd5f4c5a97fc0775638c015a",
      "7dddbb57588b4110b9f7adec33ee5a93",
      "edddea7e0d1c4f72a8b65b530f8c81ff",
      "5bf32a2c49ca4e1e8f7988cdf7dd7e00",
      "56fe1e31937a4ee4b5eb124fb13afd9d",
      "c23de31ff0ff4b68a1082652201aaae3",
      "c593139a08d24384b3dc53448b4e22e3",
      "e7c32e0161684de4b5baa43af63e75eb",
      "6f8ad34c22a8430bb18de04f717ec66c",
      "f20e106274ad4686b1b8f14d4fc65791",
      "827b16bf694840e3a487937b775d3657",
      "fe726b58245842ddbd1152788ae939dd",
      "731f24f79c7d4b2f9b640fff0f279cb3",
      "333c20a8805c4b6daa8b21a8d508b1db",
      "d174744b9adc4d1fa7574d4a57ffdd3a",
      "46e14c825294413386d4c84877d5d7fd",
      "430f7e4f8b4749ca9b10fb298594cfea",
      "cd992e0a8b8948b0ad0bbd81d1127021",
      "d9656bc9801d4e2cb534822b676d4285",
      "6c628fb66d2d4f63bcbf154d20441306",
      "d738a27fda6e40809ddd46ee42adb79c",
      "26a19755b7ac4de897caed4341797c57",
      "a4d0e244265c4535b14e3da4d48594b3",
      "b991649beab84842b386630061aa6c64",
      "acd073b1fc6e4db09a5b47ca63d666d5",
      "f19721ca7060425c87d88ae6c3df300c",
      "c456c567147d4acab71c70dbddfd3382",
      "bf513be539104f14ab259819bd92c0a6",
      "348336a703ef4580a61301cb2add5237",
      "933beea08bfd4443a7114a3e0e750e11",
      "df7d44bd9627435ba6951680cfb32e9a",
      "3d10e6d3b0ed4025ba67704c8a44c2ce",
      "f9cbf08f6e05495fabfe1e899c2785f0",
      "9ab3ecd849654238b791b821d9db02bb",
      "9d4a76fe27f44491a6fe5989e540ec1e",
      "99cc3eb8d06146d49e83fc02a04c00b0",
      "710a1546b10c4d4999a9579b6a3dc3f7",
      "97823e6a70104f378b496faa6404d884",
      "3f71fc857f4d45379c4ad79bee9e4452",
      "0f6e89b816254f27a3a52978583609d0",
      "b7a3715eb1e9438fa1f465b49a0f5c62",
      "5e0c24d7ea3b49bc93b9a06c3ee36280",
      "8fca394683df4002b78d4dc6b09d6500",
      "5b16069ed299499cba32867da02d5593",
      "984110c4cfc649f2b69d669ced3c4018",
      "b4ccbccff5164acdb32d4e16ca93b602",
      "703ad0e96cc644c29d16acc6dbc117ec",
      "cc0f29a84ab741b599925cc9ffd1b973",
      "16fbf5c1d3fd4700a1dd2e1d201f71c8",
      "a11342b3fcb74d1a8ad009cbc987a52d",
      "94edb37474e94081b1ca01d6cd93aa8c",
      "6b90ad0f36134f91b4fde09181f68a03",
      "f3c2b700b22f42cd9477569692df5c46",
      "a39edfea4d1942a685383b41c4a26783",
      "cdc2713c34b245ae8a165d95b1dff19c",
      "3df380f3791c4edd8dd279160ec4927b",
      "e0ed8a9bef044f67862330de7f532591",
      "d036a1f129324dd0baf5805839307921",
      "c6d276dab5d140918333f9e1120e23af",
      "58e6fd39ad124cc89cdc103d047cd5ed",
      "5f4e75c30eb5449f8bce0884021527d9",
      "89ac75d39b21490fa63de183eeb2a8bc",
      "e26ba9adb9574e33962d2c5bf199395c",
      "d2d285579d3440769e97c07798f36b38",
      "fc7e4b5b267447589e18605c09ec9ade",
      "08f8fb8154984330bb5fdb8f19b68652",
      "4ea4137fc1f24692a520b052288a01e8",
      "57c16a1acd9b42efa3f286f9ec8337e7",
      "b69f0857a7ef4f13bd1357813e7adba3",
      "310c8b3a837a4b04a28291066085ce37",
      "aa1ed83c4df44afb84721e6c74535c65",
      "90023be91a5d47299ed19f04facc549c",
      "307c773877ed4e56aa7c881ed142fe20",
      "0b779fed49e54c7da2c1389ee79fce3a",
      "fdd5b73b2e404f74893162bae218a7d5",
      "e353dcfb456c436c8c203cff4bba08f6",
      "a78a1ee1abe84775b57be9adbe01516c",
      "a2d67570dba1488ea2d67ddf42faf21d",
      "6802b5e93bf241e48880eedff12491db",
      "a9169da712104708bb30bbb871196737",
      "3c92c8fd886d4825a58c60118a1d1d83",
      "7daf53a5ec084c2c853d03c563d2f6d1",
      "b65469c1e9624ca9a0d7b122034bdb52",
      "9b36b4cdca444f0ab73deb30c550f472",
      "a3b1c1534580435088502dc28f84d11f",
      "b19967fb720b4103a0ef0a8d7a5cc881",
      "658718500fba4d4f88395caf7dff2854",
      "32e42dbe7e024d35aab975accc72764b",
      "bb8ff9bc52a0464ba54f5e11e674a584",
      "ab511f4bbdc64880a03edd4cbcc35d65",
      "3cd39bd9af99450ba9042bc597c6784c",
      "218a3e88331f4516baf784884ad6c7c6",
      "8209b6632dde4006a65dad6378573759",
      "2bcad9ecc92f422388348cf4ecdd9ec8",
      "61e1b97661004c20b92438d9c5a196c7",
      "2a6563af3e194b24b0954bf48d17ab48",
      "20fe5cba667b4b0e8650d24673c9120e",
      "8cf2195f2297466f90791e31abada752",
      "2d0c1597d877418195854c42059ca179",
      "267e93673c9a43d0bf513c684b86e407",
      "57c43153132e4f04819a89340d70cb78",
      "13bf0e07f12646b99d220e1d6e9f24d8",
      "cb6cf531773a4eaca15c68686383d4fc",
      "c4d6cc6ddaa841ebb8a4704cb55eb295",
      "7fdfbb7265344f6bb0bfa872e76953a8",
      "845f4e867b7e4d4a936b47395559c6fb",
      "c4204419f0a347edac585d13f878ff5a",
      "d776b6b7a0f4497a9ae1f45eff43d120",
      "6d13f87173c245e7b38872fe5c5bd034",
      "3dffa0c0107e4d789321ee5a88fe783d",
      "3c597567176b4b66bf0c7ff6db2ea205",
      "3032bc5a79024468961308cf5be68366",
      "c16e11740b8246328734fbeaa6ff18f2",
      "728cdfb03ca44ab0ba2ca32634d4b28b",
      "9679ad880b7346ccb3e181111d5d581d",
      "3f39a328a1fc418f9aa4b1ef8980359a",
      "2581f29f27324fde83e11fc245e8249e",
      "2476b85d805b4dfca894a6fd704c47cc",
      "a209e13e5edd4fe38cf4402ef9895e41",
      "cd575799319146b49449bcef4e8a5bc1",
      "292724fcdbc14f688ec8d0c25d7451a5",
      "ec031d23514e40f59f27cc7f718c6880",
      "9a88511f3b704bb7b9bfc94c7bf440e2",
      "378207ea6a66484ea701bf2e2a5148fb",
      "738f2cea0f9140cabf56ee698fdcb5d4",
      "f305a5d625494fa69394f8bb9ca4fd5e",
      "32c8282a84284412b8c803b141b71923",
      "a92c2c7beb2442b1bdd7d93e3fd25ec7",
      "73216028f52e4e5bb22ec9b2f253fcc8",
      "bc8b820f4e844f55802a06ee11001fb2",
      "8d4f4c3e1ec54d26a9ba21ecd8002161",
      "150d7cb00df346f59e6354e17ad90de9",
      "b4c50221236e4553b10d7263be5b25c0",
      "3625ddb8152941a2868a2d887fc10fc2",
      "41b80cda3884405e8e1b5d54ce883866",
      "aaac945af7084530b6f4c291565b8a0a",
      "59d517d6dc8849f393abe37f4fa7b216",
      "ed8bbfab70bf4ef19415d5ef31fc4884",
      "0eac123c5cef4fb285bbd324e038c23e",
      "4a6a8bd6b2d3489386857ffce071dfc6",
      "7589d962d83843d38ae21e119b647521",
      "42023a0cdef64d96883bb2ac0103e529",
      "915e18225c624df18bafc35730800bd3",
      "8267cfcc02fc4c9fa65b28e41a262e5f",
      "5f942e65c3374139b3714bc0baeb11bf",
      "1c27b0410d1a4ddea05b35d16cc50dd3",
      "8e6cae10d4274620a67bd53c56e15577",
      "f32b1e033cc64f4fa29357124ced8d62",
      "6ec8c63021454df7a207b798dc80d96d",
      "a5fbc9ae9f3c486f83fe4def88fc4a2b",
      "01f7f1ae83464c8abe821d687713fecb",
      "0ae83a683daa4d08a0de9158377d0ebb",
      "75d64170371846b193b47e51321ad61c",
      "4ce73e8cae8945578480918eb9cd3e47",
      "c9239f3c6be841fba140f5233ab573f8",
      "e0bf974a6bdd491b8b39f7b44268e353",
      "7b3f3d9b089d44dd8de4ded3323e23f2",
      "6ef159b702c14bf99062879830e77076",
      "c5f1d5aae6294190a209c426b7bdbb8e",
      "5e6a9ee5ff9741e1b72673b948135151",
      "e53eda2ce4de4219bf1ef2dd1ef4fb05",
      "35243281784d41e58712a5911b4d747d",
      "090cc4cf91dd456fb36a0b69a85d4bd3",
      "451fdae4931243f2b0045b23600a3355",
      "e2aca07674f3488cb7f17806032ea30c",
      "2961a028e99d4473ac3d0e084b346006",
      "3f2a47610b2142c781b00f276df490e1",
      "b380046a1f234aa1819bdea1267c1e88",
      "94e7e327edbc458ca24b99925f23db1b",
      "6c99b4a233694e36ad91af73deaaeef7",
      "a3d3b93bcb4e4d90ba95b459ce17aff8",
      "cc52262bdce641c3b34f737b51acd33c",
      "7f95606d46294784ab0ce0d7dfaca3ca",
      "beb340a47f8b43d6902f5bc1758473f7",
      "b54d15edd9064575839921bf8fa09dc1",
      "d9105e0f7cc24d18905941ae953b3539",
      "0c690eb6f6134e04812903b4a7230fca",
      "ab5a3447e5c546978d13ebce81ba9c37",
      "faa37081fef04abbb08f8a43df983e14",
      "010b81a7902f41c6ac3a093cdb62d886",
      "1d4dea3aea744127ad01c9c5d14f93bb",
      "a28992a9dfe14f97a6d0942cdaa988d0",
      "83cc7fe94ad94a0fb8c2b54a4fcbf8f2",
      "9ba888e85d0f4e2e8dec1fd8c4cc7564",
      "c932a890a9b14b7ab90a3ef73ff54827",
      "ff07905cd9c44033a2c55bada815ae59",
      "3613e4f1bd9c49d39b7ab285aaa5dce9",
      "efc64444bfe24fad9256cf18d5634690",
      "ac41869aa5fa4a81a34adfca3e8ef21c",
      "09bad9b37fa141509acd53994e0bc469",
      "71897299e2304365b897f1c5c470a1b0",
      "b1eef0bc7a244787895443c84cfb5294",
      "1c4aa81564874ea38740c9750e9de665",
      "78f7e732016145c3905688a99d1f4f4c",
      "5f954e8f33974944ae716c121b44d9cb",
      "498c0d68c1c244a8bdf70e6779e59d52",
      "511030c84309460a8a177788240c8160",
      "8bba41bbe8284621ba5335b1c08d50ba",
      "cdd33eb9dccd41a6b8c066cffefa8b38",
      "87c58b2ab8d443078e6b6c1fce1144fd",
      "7b1ab6a6f3fc4728ada0cd530328bbcc",
      "085d87a8f91841edb4af5d59b91750e1",
      "b771c42600a646c9a22934d37fd10f04",
      "e5d500185acc406c8d584d6fc4254971",
      "9860872ebab94911965a291248454439",
      "d6019d5ce9a84497bab49a6e69f5a2e2",
      "c5986ff8f35c4f2789d1de7b1eda5154",
      "dccd7b13ada64149ba8c9ea07f0b8a32",
      "9e7b5f90d49d43b5b86ffac6636f4134",
      "8bf88d61184d4d2699310c8ff28bb245",
      "6da6e7f4ce314756a64f805f47cf50fc",
      "9b9411532935406c87df540f1731d41b",
      "cf044ffa2241408abb93ef6194d390df",
      "bf768899b6554f8b95f39d640ff311aa",
      "52f1d942400b406aa9481bab15f6e18a",
      "f7fb7a421a504237ae215f181682f655",
      "506ccd5653fd4a93868f5bbfe79a4ec0",
      "67196e054c40478c87b915f402c287c4",
      "c9bb6b474ae9424f8b58fbc8316c0de2",
      "09f966f2f50f4574962ea36badb4fbd2",
      "ed5dab64b3bb483ebb070fd315bebd99",
      "937491fefda54667b9ac7ee86033afb7",
      "ef5ba605963f414d982a79e41b21193e",
      "82a0a5f535c8459e88fd442c48ba7c41",
      "dfd24540f4674612bd5911d640d999ae",
      "6f7af5b5d16948f795e37fc08f0ecbc4",
      "388cca894e0048c080ba80bc9489722a",
      "9b9c83c015204ba58dd1787ee40d5ed8",
      "7fd779a2f2214ef99afa8c53d045736a",
      "6b5ef2305c3c462295bb6d4be253d4ed",
      "abf334dd9a3b40e79dc1ef0e165f80d0",
      "a7a3882e5d804c48b287fac7e5bb6ede",
      "65449285b7474d36801b103db00f8f7b",
      "957b61f7e7574600bded6fd4725a47cc",
      "d571ccd81f1b4646be0e2efee99c601a",
      "85e35ceec0ae4c02bb3bb4008d1455ee",
      "406b102a547e4e1187d106a83ba1c918",
      "a18481b3d84b46b88b7991f481640557",
      "ebfe534a6df4428ba82146c8257bd3b1",
      "189b94b9d80948bda1967c23c91d43fa",
      "1e71a74e800644238eeadf30be6f1289",
      "feb15b1963be4358981bb6b7a98aebf3",
      "997254fb091a4ffe9ad0dafd9b12be06",
      "04a04587f49d4b6e9300f0d1ea3e90e3"
     ]
    },
    "id": "V5pboEh_Bm3P",
    "outputId": "ba91090a-eb76-4240-b07e-4cb122b46fe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda\n",
      "Loading dataset slices...\n",
      "Initial Load: Train=5500, Test=600\n",
      "Filtering empty sentences...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40290352cc847628c6b9717d41291b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/5500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e3f2ccd43041d084a44cc385d65401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Casting audio column...\n",
      "Final Train Size: 5000 | Final Test Size: 500\n",
      "Building vocabulary...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c70d9702d294a73a154de265a0fde67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scanning Vocab:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 47\n",
      "Model Fixed: Added LogSoftmax.\n",
      "--- STARTING 2x SUBSAMPLING TEST ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad47a9df3c4492d8f99a88587fe0e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rapid Training:   0%|          | 0/2001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 0 | Loss: 23.6020\n",
      "Pred: جیlیlجlیlیlیlیlیصقlجیجیlمlصlقlقآیقlآhlصقآقlآhآhآhقکآlصبیقآقآقجقجیآۀlقۀآlیمقآجقlآhآقlآlقlآقlقآتآlقصhجتlقlیآhیآمlجlمقآقآیآتlصآقlقlتlیlیlیقlیlیجیجتیlجlیج\n",
      "------------------------------\n",
      "\n",
      "Step 20 | Loss: 3.0984\n",
      "Pred: \n",
      "------------------------------\n",
      "\n",
      "Step 40 | Loss: 3.0603\n",
      "Pred: \n",
      "------------------------------\n",
      "\n",
      "Step 60 | Loss: 3.0382\n",
      "Pred: \n",
      "------------------------------\n",
      "\n",
      "Step 80 | Loss: 2.9777\n",
      "Pred: \n",
      "------------------------------\n",
      "\n",
      "Step 100 | Loss: 2.9329\n",
      "Pred: \n",
      "------------------------------\n",
      "\n",
      "Step 120 | Loss: 2.8796\n",
      "Pred: ا\n",
      "------------------------------\n",
      "\n",
      "Step 140 | Loss: 2.7677\n",
      "Pred: \n",
      "------------------------------\n",
      "\n",
      "Step 160 | Loss: 2.6179\n",
      "Pred: \n",
      "------------------------------\n",
      "\n",
      "Step 180 | Loss: 2.3970\n",
      "Pred: پ\n",
      "------------------------------\n",
      "\n",
      "Step 200 | Loss: 2.1259\n",
      "Pred: پد\n",
      "------------------------------\n",
      "\n",
      "Step 220 | Loss: 1.6970\n",
      "Pred: پاااا د\n",
      "------------------------------\n",
      "\n",
      "Step 240 | Loss: 1.2027\n",
      "Pred: پزن ر ا زنو نکشد\n",
      "------------------------------\n",
      "\n",
      "Step 260 | Loss: 0.8147\n",
      "Pred: پ نز ر صرا بان صوران کلا ب شدند\n",
      "------------------------------\n",
      "\n",
      "Step 280 | Loss: 0.5083\n",
      "Pred: پس از چنوزی در صحرا بازواون و صورهمان کلا برز شد\n",
      "------------------------------\n",
      "\n",
      "Step 300 | Loss: 0.2531\n",
      "Pred: پس از چندرروزی در صحرا بازوان و صورتهامان کاملا برزه شد\n",
      "------------------------------\n",
      "\n",
      "Step 320 | Loss: 0.1139\n",
      "Pred: پس از چند روزی در صحرا بزوان و صورتهامان کاملا برنزه شدند\n",
      "------------------------------\n",
      "\n",
      "Step 340 | Loss: 0.0516\n",
      "Pred: پس از چند روزی در صحرا بازوان و صورتهایمان کاملا برنزه شدند\n",
      "Ref:  پس از چند روزی در صحرا بازوان و صورتهایمان کاملا برنزه شدند\n",
      "\n",
      ">>> VICTORY! 2x Subsampling fixed the bottleneck.\n",
      "Evaluation function updated. You can now run the training loop.\n",
      "\n",
      "--- Starting Fixed Training ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bdf44a88c9c4336abdd368600a9398c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Average Loss: 4.0422\n",
      "Test WER: 1.00\n",
      "Test CER: 1.00\n",
      "Pred: \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04f5263132e412f8c7d1eb89a9a0da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 Average Loss: 3.0149\n",
      "Test WER: 1.00\n",
      "Test CER: 1.00\n",
      "Pred: \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48e0c35313c45c8b16357da6feee6e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 Average Loss: 2.9415\n",
      "Test WER: 1.00\n",
      "Test CER: 0.97\n",
      "Pred: ا\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563719ee20c44e9b807beb2062b8262c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 Average Loss: 2.5390\n",
      "Test WER: 1.00\n",
      "Test CER: 0.77\n",
      "Pred: ای اب د ی ا کایشای سبادشاششی\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f3f0a3f76f4ab9bbd53c138a1fb272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 Average Loss: 1.9900\n",
      "Test WER: 1.01\n",
      "Test CER: 0.57\n",
      "Pred: مد ب تممنابدر مزتمی ان کرای شامامنمی دسندی مب منا دین بیش راشابشی\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01d57b0792e4837a4a7d348bba67309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 Average Loss: 1.6660\n",
      "Test WER: 0.99\n",
      "Test CER: 0.56\n",
      "Pred: مخد بتراب در زتمکامنکایشمهمنمی پسندی وب ملاقدن بیسراشابشی\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521c236728de40d08bbd0db2c6bec927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 Average Loss: 1.4533\n",
      "Test WER: 0.98\n",
      "Test CER: 0.51\n",
      "Pred: مفد بت ملاب دار زتمیخامکای شمامن می سندی مب ملاقدن بیسراشا بشیم\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae06e03540124a62b76cd60c04dcd3e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 Average Loss: 1.3000\n",
      "Test WER: 0.97\n",
      "Test CER: 0.50\n",
      "Pred: مخد بت ملاب دار وزدمیخان کری شمام من میپسندی وب ملاق دن بیسراشا بشیم\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edddea7e0d1c4f72a8b65b530f8c81ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 Average Loss: 1.1827\n",
      "Test WER: 0.97\n",
      "Test CER: 0.47\n",
      "Pred: مخی بت ملاب دار وزتومیخام کاگی شما ام منمیپسندی وب ملاق دین بیشراشابشیم\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333c20a8805c4b6daa8b21a8d508b1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10 Average Loss: 1.0883\n",
      "Test WER: 0.96\n",
      "Test CER: 0.46\n",
      "Pred: مخد بت ملاب دار بزتمخام کرگی شما هم من میپسندی بب ملاق د ان بیسراشا بشیم\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd073b1fc6e4db09a5b47ca63d666d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11 Average Loss: 1.0014\n",
      "Test WER: 0.96\n",
      "Test CER: 0.45\n",
      "Pred: مخید مت ملاب دارم و زتمیخام جاگی شما آملمیپسندی وب ملاق د ان بیسراشنا بشیم\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99cc3eb8d06146d49e83fc02a04c00b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12 Average Loss: 0.9233\n",
      "Test WER: 0.96\n",
      "Test CER: 0.45\n",
      "Pred: مخد بت مراب دارب و ازت میام کاگ شما ام من میپسندی وب ملاقدا ان بیسراشنابشیم\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703ad0e96cc644c29d16acc6dbc117ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13 Average Loss: 0.8570\n",
      "Test WER: 0.96\n",
      "Test CER: 0.45\n",
      "Pred: مخد بتو مراب دارم و ازتمهام کاگی شما م مر میپزندی وب ملاقدا ان بیسراشنابشیم\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d036a1f129324dd0baf5805839307921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14 Average Loss: 0.7903\n",
      "Test WER: 0.95\n",
      "Test CER: 0.45\n",
      "Pred: مخید مت منرابه دار و ازت میهام کاگی شما ام من میپسندی وب ملاقدا ان بیسراشنابشیم\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69f0857a7ef4f13bd1357813e7adba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15 Average Loss: 0.7243\n",
      "Test WER: 0.95\n",
      "Test CER: 0.45\n",
      "Pred: مخل متو نلاب دارا و ازت  میهامکاگی شماهم مل میپسندی وب ملاقد انبیسر راش نابشیم\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9169da712104708bb30bbb871196737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16 Average Loss: 0.6698\n",
      "Test WER: 0.93\n",
      "Test CER: 0.44\n",
      "Pred: مخل متو نراب دارب و ازتمام جاگ شماهم ملمیپسندی وب ملاقد انبیسراشنابشیم\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd39bd9af99450ba9042bc597c6784c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17 Average Loss: 0.6145\n",
      "Test WER: 0.94\n",
      "Test CER: 0.44\n",
      "Pred: مخد متو نداب دار و ازت میامگگی شماهمل میپسندی وب ملاق د انبیسراشناب شیم\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13bf0e07f12646b99d220e1d6e9f24d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18 Average Loss: 0.5626\n",
      "Test WER: 0.92\n",
      "Test CER: 0.44\n",
      "Pred: مخیل متونلاب دار وه ازتمیامجاگ شما امل میپسندی وب ملاقد انبیسراشنا بشیم\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16e11740b8246328734fbeaa6ff18f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19 Average Loss: 0.5204\n",
      "Test WER: 0.92\n",
      "Test CER: 0.44\n",
      "Pred: مخیل متو منراق دارب و ازت میخامکاگ شما هم من میپسندی وب ملاقد انبیسراشنابشیم\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378207ea6a66484ea701bf2e2a5148fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20 Average Loss: 0.4747\n",
      "Test WER: 0.94\n",
      "Test CER: 0.44\n",
      "Pred: مخیل متو نراب دار و اعزد میهام کاگی شما هآمن میپسندی وب ملاقد انبیسر راشنا بشیم\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b80cda3884405e8e1b5d54ce883866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21 Average Loss: 0.4330\n",
      "Test WER: 0.92\n",
      "Test CER: 0.43\n",
      "Pred: مخیل مطو نراق دارب و عزد میکامکاک شما همل میپسندی وب ملاقد انبیسراش نا بشیم\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c27b0410d1a4ddea05b35d16cc50dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22 Average Loss: 0.3993\n",
      "Test WER: 0.91\n",
      "Test CER: 0.43\n",
      "Pred: مخل مت منرابه دارب و عزد میکامکگ شمامن میپسندی وب ملاقد ان بیسراشنا بشیم\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3f3d9b089d44dd8de4ded3323e23f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23 Average Loss: 0.3648\n",
      "Test WER: 0.92\n",
      "Test CER: 0.44\n",
      "Pred: مخل متومنراب دارب و ازتمهامکگی شما امل میپسندی وب ملاقد انبیسراشنا بشیم\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b380046a1f234aa1819bdea1267c1e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24 Average Loss: 0.3329\n",
      "Test WER: 0.94\n",
      "Test CER: 0.44\n",
      "Pred: مخیل متونعراقه دارب و عزت مکامکگ شماهمل میپذندی وب ملاقد انبیشراش نا بشیم\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa37081fef04abbb08f8a43df983e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25 Average Loss: 0.3108\n",
      "Test WER: 0.92\n",
      "Test CER: 0.44\n",
      "Pred: مخل متونعراق دار و عزت مکامکگ شما همل میپسندی وب معلاقد ان بیسراشنابشیم\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09bad9b37fa141509acd53994e0bc469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26 Average Loss: 0.2806\n",
      "Test WER: 0.92\n",
      "Test CER: 0.43\n",
      "Pred: م خل متو نعرا به دارب و عزت میهام کاگ شمها آمل میپسندی وب معلاقد ان بیسراشتنا بشیم\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b1ab6a6f3fc4728ada0cd530328bbcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27 Average Loss: 0.2584\n",
      "Test WER: 0.93\n",
      "Test CER: 0.44\n",
      "Pred: مخل مطو منععراقه دارب وه اعزت مکام کاگ شماامل میپسندهی وب معلاقد انبیشراش نابشیم\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9411532935406c87df540f1731d41b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28 Average Loss: 0.2363\n",
      "Test WER: 0.93\n",
      "Test CER: 0.43\n",
      "Pred: مخل متو منعرابه دار وه اعزت میکام کاکگ شماهمر میپسندهی وب معلاقد انبیسراشنا بشیم\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef5ba605963f414d982a79e41b21193e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29 Average Loss: 0.2154\n",
      "Test WER: 0.91\n",
      "Test CER: 0.43\n",
      "Pred: مخل متو مرابه دارب و عزت میکامکعگ شما امن میپسندهی وب معلاقد ان بیسراش نا بشیم\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957b61f7e7574600bded6fd4725a47cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30 Average Loss: 0.2006\n",
      "Test WER: 0.95\n",
      "Test CER: 0.43\n",
      "Pred: مخل مطو معراقه دارم وه عزت میهامکاگی شما همل میپسندهی وب ملاقد ان بیسراش نو بشیم\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import librosa\n",
    "from datasets import load_dataset, Audio\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from jiwer import wer, cer\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "\n",
    "# Ignore minor warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Redirect stderr to devnull to hide the C++ multiprocessing errors\n",
    "# WARNING: This hides ALL errors, so remove it if your code crashes silently.\n",
    "sys.stderr = open(os.devnull, 'w')\n",
    "\n",
    "# ... Run your training loop here ...\n",
    "\n",
    "# Restore stderr after the loop so you can see future errors\n",
    "# sys.stderr = sys.__stderr__\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "class Config:\n",
    "    # Audio Params\n",
    "    SAMPLE_RATE = 16000\n",
    "    N_MFCC = 13\n",
    "    N_FFT = 400\n",
    "    HOP_LENGTH = 160\n",
    "    # 39 Features = 13 MFCC + 13 Delta + 13 Delta-Delta\n",
    "    N_FEATURES = 39\n",
    "\n",
    "    # Dataset Sizes (Small slices to prevent Colab Crash)\n",
    "    TRAIN_SIZE = 5000\n",
    "    TEST_SIZE = 500\n",
    "\n",
    "    # Model Params\n",
    "    HIDDEN_SIZE = 256\n",
    "    NUM_LAYERS = 3\n",
    "    DROPOUT = 0.3\n",
    "\n",
    "    # Training Params\n",
    "    BATCH_SIZE = 32\n",
    "    LR = 1e-4\n",
    "    EPOCHS = 30\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Special Tokens\n",
    "    BLANK_TOKEN = \"[BLANK]\"\n",
    "\n",
    "config = Config()\n",
    "print(f\"Running on: {config.DEVICE}\")\n",
    "\n",
    "# --- 2. DATA LOADING (OPTIMIZED FOR COLAB) ---\n",
    "def load_and_prepare_data():\n",
    "    print(\"Loading dataset slices...\")\n",
    "\n",
    "    # TRICK: Instead of loading \"train\" (all 300GB), we load \"train[:5500]\"\n",
    "    # This tells Hugging Face to only process the first few rows.\n",
    "    # We load slightly more to account for filtering.\n",
    "    train_split_str = f\"train[:{config.TRAIN_SIZE + 500}]\"\n",
    "    test_split_str = f\"test[:{config.TEST_SIZE + 100}]\"\n",
    "\n",
    "    # 1. Load Slices (This is fast and low-RAM)\n",
    "    train_ds = load_dataset(\"hezarai/common-voice-13-fa\", split=train_split_str, trust_remote_code=True)\n",
    "    test_ds = load_dataset(\"hezarai/common-voice-13-fa\", split=test_split_str, trust_remote_code=True)\n",
    "\n",
    "    print(f\"Initial Load: Train={len(train_ds)}, Test={len(test_ds)}\")\n",
    "\n",
    "    # 2. Drop unnecessary columns (Keep only audio/sentence)\n",
    "    cols_to_keep = [\"audio\", \"sentence\"]\n",
    "    train_ds = train_ds.select_columns(cols_to_keep)\n",
    "    test_ds = test_ds.select_columns(cols_to_keep)\n",
    "\n",
    "    # 3. Filter FIRST (Before casting audio)\n",
    "    # This cleans the text without decoding the heavy MP3 files yet.\n",
    "    print(\"Filtering empty sentences...\")\n",
    "    def is_valid(x):\n",
    "        return x[\"sentence\"] is not None and len(x[\"sentence\"]) > 2\n",
    "\n",
    "    train_ds = train_ds.filter(is_valid)\n",
    "    test_ds = test_ds.filter(is_valid)\n",
    "\n",
    "    # 4. Truncate to exact requested size\n",
    "    train_ds = train_ds.select(range(min(len(train_ds), config.TRAIN_SIZE)))\n",
    "    test_ds = test_ds.select(range(min(len(test_ds), config.TEST_SIZE)))\n",
    "\n",
    "    # 5. Cast Audio SECOND (Now safe)\n",
    "    # This enables on-the-fly decoding only for our small subset\n",
    "    print(\"Casting audio column...\")\n",
    "    train_ds = train_ds.cast_column(\"audio\", Audio(sampling_rate=config.SAMPLE_RATE))\n",
    "    test_ds = test_ds.cast_column(\"audio\", Audio(sampling_rate=config.SAMPLE_RATE))\n",
    "\n",
    "    return train_ds, test_ds\n",
    "\n",
    "train_ds, test_ds = load_and_prepare_data()\n",
    "print(f\"Final Train Size: {len(train_ds)} | Final Test Size: {len(test_ds)}\")\n",
    "\n",
    "# --- 3. VOCABULARY & NORMALIZATION ---\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = str(text).lower().strip()\n",
    "    # Normalize Persian characters\n",
    "    text = text.replace('ك', 'ک').replace('ي', 'ی').replace('ئ', 'ی').replace('ى', 'ی')\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def build_vocab(dataset):\n",
    "    print(\"Building vocabulary...\")\n",
    "    vocab = set()\n",
    "    # We iterate over the dataset to find all unique chars\n",
    "    for item in tqdm(dataset, desc=\"Scanning Vocab\"):\n",
    "        vocab.update(normalize_text(item[\"sentence\"]))\n",
    "\n",
    "    sorted_vocab = sorted(list(vocab))\n",
    "\n",
    "    # 0 is reserved for CTC Blank\n",
    "    char2id = {c: i + 1 for i, c in enumerate(sorted_vocab)}\n",
    "    char2id[config.BLANK_TOKEN] = 0\n",
    "\n",
    "    id2char = {i: c for c, i in char2id.items()}\n",
    "    return char2id, id2char\n",
    "\n",
    "char2id, id2char = build_vocab(train_ds)\n",
    "VOCAB_SIZE = len(char2id)\n",
    "print(f\"Vocabulary Size: {VOCAB_SIZE}\")\n",
    "\n",
    "# --- 4. UPDATE THIS FUNCTION ---\n",
    "def process_batch(batch):\n",
    "    # ... (Keep existing setup code) ...\n",
    "    batch_features = []\n",
    "    batch_labels = []\n",
    "    batch_input_lens = []\n",
    "    batch_label_lens = []\n",
    "\n",
    "    for audio_data, text in zip(batch[\"audio\"], batch[\"sentence\"]):\n",
    "        try:\n",
    "            if audio_data is None: continue\n",
    "            audio_array = audio_data[\"array\"]\n",
    "            if isinstance(audio_array, list): audio_array = np.array(audio_array)\n",
    "            if len(audio_array) < 400: continue\n",
    "\n",
    "            # Extract MFCC\n",
    "            mfcc = librosa.feature.mfcc(y=audio_array, sr=config.SAMPLE_RATE, n_mfcc=config.N_MFCC, n_fft=config.N_FFT, hop_length=config.HOP_LENGTH)\n",
    "            delta = librosa.feature.delta(mfcc)\n",
    "            delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "            feats = np.vstack([mfcc, delta, delta2]).T.astype(np.float32)\n",
    "\n",
    "            # --- PERMANENT INSTANCE NORM FIX ---\n",
    "            # Normalize each file individually to Mean=0, Std=1\n",
    "            # This is critical for convergence\n",
    "            mean = np.mean(feats, axis=0)\n",
    "            std = np.std(feats, axis=0)\n",
    "            feats = (feats - mean) / (std + 1e-9)\n",
    "            # -----------------------------------\n",
    "\n",
    "            norm_text = normalize_text(text)\n",
    "            label_ids = [char2id[c] for c in norm_text if c in char2id]\n",
    "\n",
    "            if len(label_ids) > 0:\n",
    "                batch_features.append(feats)\n",
    "                batch_labels.append(label_ids)\n",
    "                batch_input_lens.append(feats.shape[0])\n",
    "                batch_label_lens.append(len(label_ids))\n",
    "\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    return {\n",
    "        \"input_features\": batch_features,\n",
    "        \"labels\": batch_labels,\n",
    "        \"input_lengths\": batch_input_lens,\n",
    "        \"label_lengths\": batch_label_lens\n",
    "    }\n",
    "\n",
    "# Re-apply transform\n",
    "train_ds.set_transform(process_batch)\n",
    "test_ds.set_transform(process_batch)\n",
    "\n",
    "# --- 5. DATA COLLATOR ---\n",
    "\n",
    "def data_collator(batch):\n",
    "    # Filter out placeholder values (invalid samples that returned empty data)\n",
    "    # An item is considered invalid if its label_lengths is 0\n",
    "    batch = [x for x in batch if x[\"label_lengths\"] > 0]\n",
    "\n",
    "    # If the batch is empty after filtering, the rest of the function\n",
    "    # will naturally produce empty tensors/lists, which DataLoader can handle.\n",
    "\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    in_lens = []\n",
    "    label_lens = []\n",
    "\n",
    "    for item in batch:\n",
    "        inputs.append(torch.tensor(item[\"input_features\"]))\n",
    "        labels.append(torch.tensor(item[\"labels\"]))\n",
    "        in_lens.append(item[\"input_lengths\"])\n",
    "        label_lens.append(item[\"label_lengths\"])\n",
    "\n",
    "    if not inputs: # Handle case where all samples were filtered out\n",
    "        return (\n",
    "            torch.empty(0, config.N_FEATURES),  # inputs_padded\n",
    "            torch.empty(0, dtype=torch.long),   # labels_padded\n",
    "            torch.empty(0, dtype=torch.long),   # in_lens\n",
    "            torch.empty(0, dtype=torch.long)    # label_lens\n",
    "        )\n",
    "\n",
    "    # Sort for PackedSequence (Descedning order)\n",
    "    zipped = zip(inputs, labels, in_lens, label_lens)\n",
    "    sorted_data = sorted(zipped, key=lambda x: x[2], reverse=True)\n",
    "    inputs, labels, in_lens, label_lens = zip(*sorted_data)\n",
    "\n",
    "    inputs = list(inputs)\n",
    "    labels = list(labels)\n",
    "    in_lens = torch.tensor(in_lens, dtype=torch.long)\n",
    "    label_lens = torch.tensor(label_lens, dtype=torch.long)\n",
    "\n",
    "    # Pad\n",
    "    inputs_padded = pad_sequence(inputs, batch_first=True)\n",
    "    labels_padded = pad_sequence(labels, batch_first=True, padding_value=0)\n",
    "\n",
    "    return inputs_padded, labels_padded, in_lens, label_lens\n",
    "\n",
    "# Create Loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=config.BATCH_SIZE, collate_fn=data_collator, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_ds, batch_size=config.BATCH_SIZE, collate_fn=data_collator, shuffle=False, num_workers=2)\n",
    "\n",
    "# --- 6. FINAL FIXED MODEL (2x Subsampling + LogSoftmax) ---\n",
    "\n",
    "class CNN_BiLSTM_ASR(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # CNN: Reduces Time by 2x\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Calc Input Size (Same as before)\n",
    "        feat_dim = input_dim\n",
    "        feat_dim = (feat_dim + 2*1 - 3)//2 + 1\n",
    "        feat_dim = (feat_dim + 2*1 - 3)//1 + 1\n",
    "        self.lstm_input_size = 32 * feat_dim\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.lstm_input_size,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=config.DROPOUT\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_dim * 2, vocab_size)\n",
    "\n",
    "    def forward(self, x, input_lengths):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.cnn(x)\n",
    "\n",
    "        B, C, T_new, F_new = x.shape\n",
    "        x = x.permute(0, 2, 1, 3).reshape(B, T_new, C * F_new)\n",
    "\n",
    "        new_input_lengths = torch.div(input_lengths, 2, rounding_mode='floor')\n",
    "\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        logits = self.classifier(lstm_out)\n",
    "\n",
    "        # --- CRITICAL FIX ---\n",
    "        # Convert Logits to Log-Probabilities for CTC Loss\n",
    "        log_probs = F.log_softmax(logits, dim=2)\n",
    "\n",
    "        return log_probs, new_input_lengths\n",
    "\n",
    "print(\"Model Fixed: Added LogSoftmax.\")\n",
    "\n",
    "# --- DEBUGGING: OVERFIT (2x Subsampling + Instance Norm) ---\n",
    "\n",
    "print(\"--- STARTING 2x SUBSAMPLING TEST ---\")\n",
    "\n",
    "# 1. Grab Batch\n",
    "batch = next(iter(train_loader))\n",
    "inputs, labels, in_lens, label_lens = [x.to(config.DEVICE) for x in batch]\n",
    "\n",
    "# --- INSTANCE NORM (Keep this!) ---\n",
    "mean = inputs.mean(dim=1, keepdim=True)\n",
    "std = inputs.std(dim=1, keepdim=True)\n",
    "inputs = (inputs - mean) / (std + 1e-5)\n",
    "# ----------------------------------\n",
    "\n",
    "# 2. Re-init Model (2x Version)\n",
    "model = CNN_BiLSTM_ASR(config.N_FEATURES, config.HIDDEN_SIZE, config.NUM_LAYERS, VOCAB_SIZE)\n",
    "model.to(config.DEVICE)\n",
    "model.train()\n",
    "\n",
    "# 3. Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CTCLoss(blank=0, zero_infinity=False)\n",
    "\n",
    "# 4. Loop\n",
    "pbar = tqdm(range(2001), desc=\"Rapid Training\")\n",
    "\n",
    "for i in pbar:\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward\n",
    "    logits, new_in_lens = model(inputs, in_lens)\n",
    "\n",
    "    # Loss\n",
    "    logits_permuted = logits.permute(1, 0, 2)\n",
    "    loss = criterion(logits_permuted, labels, new_in_lens, label_lens)\n",
    "\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    pbar.set_postfix({\"Loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    if i % 20 == 0:\n",
    "        with torch.no_grad():\n",
    "            pred_text = decode_prediction(logits[0], new_in_lens[0])\n",
    "            ref_ids = labels[0][:label_lens[0]].cpu().tolist()\n",
    "            ref_text = \"\".join([id2char[idx] for idx in ref_ids])\n",
    "\n",
    "            print(f\"\\nStep {i} | Loss: {loss.item():.4f}\")\n",
    "            print(f\"Pred: {pred_text}\")\n",
    "\n",
    "            if pred_text == ref_text:\n",
    "                print(f\"Ref:  {ref_text}\")\n",
    "                print(\"\\n>>> VICTORY! 2x Subsampling fixed the bottleneck.\")\n",
    "                break\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "# --- FIX: UPDATED EVALUATION FUNCTION (TUPLE AWARE) ---\n",
    "\n",
    "def decode_prediction(logits, input_len):\n",
    "    \"\"\"\n",
    "    Greedy Decoder for CTC.\n",
    "    logits: (Time, Vocab) - Single sample\n",
    "    input_len: int - Scalar\n",
    "    \"\"\"\n",
    "    # Argmax over the vocabulary dimension\n",
    "    tokens = torch.argmax(logits, dim=-1) # Shape: (Time)\n",
    "\n",
    "    decoded_preds = []\n",
    "    # Collapse repeats and blanks\n",
    "    for i in range(input_len):\n",
    "        token = tokens[i].item()\n",
    "        if token != 0: # 0 is blank\n",
    "            if i == 0 or token != tokens[i-1].item():\n",
    "                decoded_preds.append(id2char[token])\n",
    "    return \"\".join(decoded_preds)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    refs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            if batch is None or batch[0].shape[0] == 0: continue\n",
    "\n",
    "            inputs, labels, in_lens, label_lens = [x.to(config.DEVICE) for x in batch]\n",
    "\n",
    "            # --- FIX: Unpack the tuple correctly ---\n",
    "            log_probs, new_lens = model(inputs, in_lens)\n",
    "\n",
    "            for i in range(len(inputs)):\n",
    "                # Use the 'new_lens' from the model (CNN adjusted length)\n",
    "                pred_text = decode_prediction(log_probs[i], new_lens[i])\n",
    "\n",
    "                # Get Reference\n",
    "                ref_ids = labels[i][:label_lens[i]].cpu().tolist()\n",
    "                ref_text = \"\".join([id2char[idx] for idx in ref_ids])\n",
    "\n",
    "                preds.append(pred_text)\n",
    "                refs.append(ref_text)\n",
    "\n",
    "    if len(preds) == 0:\n",
    "        return 1.0, 1.0, \"None\", \"None\"\n",
    "\n",
    "    # Calculate Metrics\n",
    "    w = wer(refs, preds)\n",
    "    c = cer(refs, preds)\n",
    "    return w, c, preds[0], refs[0]\n",
    "\n",
    "print(\"Evaluation function updated. You can now run the training loop.\")\n",
    "\n",
    "\n",
    "# --- 7. FINAL TRAINING EXECUTION ---\n",
    "\n",
    "model = CNN_BiLSTM_ASR(config.N_FEATURES, config.HIDDEN_SIZE, config.NUM_LAYERS, VOCAB_SIZE)\n",
    "model.to(config.DEVICE)\n",
    "\n",
    "# Use a safe Learning Rate\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4) # 0.0003\n",
    "criterion = nn.CTCLoss(blank=0, zero_infinity=False)\n",
    "\n",
    "print(f\"\\n--- Starting Fixed Training ---\")\n",
    "\n",
    "for epoch in range(config.EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "\n",
    "    for batch in pbar:\n",
    "        if batch is None or batch[0].shape[0] == 0: continue\n",
    "\n",
    "        inputs, labels, in_lens, label_lens = [x.to(config.DEVICE) for x in batch]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Returns log_probs now!\n",
    "        log_probs, new_input_lengths = model(inputs, in_lens)\n",
    "\n",
    "        # CTC expects (Time, Batch, Vocab)\n",
    "        log_probs_permuted = log_probs.permute(1, 0, 2)\n",
    "\n",
    "        loss = criterion(log_probs_permuted, labels, new_input_lengths, label_lens)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        pbar.set_postfix({\"Loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    avg_loss = total_loss / num_batches if num_batches > 0 else 0.0\n",
    "    print(f\"\\nEpoch {epoch+1} Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Eval\n",
    "    test_wer, test_cer, sample_pred, sample_ref = evaluate(model, test_loader)\n",
    "    print(f\"Test WER: {test_wer:.2f}\")\n",
    "    print(f\"Test CER: {test_cer:.2f}\")\n",
    "    print(f\"Pred: {sample_pred}\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

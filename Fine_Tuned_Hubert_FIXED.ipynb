{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "gpuType": "T4",
   "provenance": []
  },
  "accelerator": "GPU",
  "kaggle": {
   "accelerator": "gpu"
  },
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install -U transformers\n",
    "%pip install evaluate\n",
    "%pip install jiwer\n",
    "%pip install --upgrade torchcodec"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Al1hwYQSJAHg",
    "outputId": "f096de66-1d96-42a5-b4f1-a4fe1d60a19a"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (22.0.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.11.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.12.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: jiwer in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from jiwer) (8.3.1)\n",
      "Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.12/dist-packages (from jiwer) (3.14.3)\n",
      "Requirement already satisfied: torchcodec in /usr/local/lib/python3.12/dist-packages (0.9.1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Local Inference on GPU\n",
    "Model page: https://huggingface.co/jonatasgrosman/exp_w2v2t_fa_hubert_s801\n",
    "\n",
    "\u26a0\ufe0f If the generated code snippets do not work, please open an issue on either the [model repo](https://huggingface.co/jonatasgrosman/exp_w2v2t_fa_hubert_s801)\n",
    "\t\t\tand/or on [huggingface.js](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/model-libraries-snippets.ts) \ud83d\ude4f"
   ],
   "metadata": {
    "id": "No0Lmg8AJAHi"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"jonatasgrosman/exp_w2v2t_fa_hubert_s801\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8uuQ8xZJAHj",
    "outputId": "6ef2dfa0-d276-4cbd-de79-93d05cf509d5"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "Device set to use cuda:0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Load model directly\n",
    "from transformers import AutoProcessor, AutoModelForCTC\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"jonatasgrosman/exp_w2v2t_fa_hubert_s801\")\n",
    "model = AutoModelForCTC.from_pretrained(\"jonatasgrosman/exp_w2v2t_fa_hubert_s801\")"
   ],
   "metadata": {
    "id": "qrhmRZu2JAHk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install --upgrade datasets\n",
    "\n",
    "import torch\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset, Audio\n",
    "from transformers import AutoProcessor, AutoModelForCTC\n",
    "from evaluate import load\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "MODEL_ID = \"jonatasgrosman/exp_w2v2t_fa_hubert_s801\"\n",
    "DATASET_ID = \"hezarai/common-voice-13-fa\"\n",
    "SPLIT = \"test\"  # Assessing performance on the held-out test set\n",
    "SAMPLING_RATE = 16000\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 8 # Adjust based on your GPU memory (lower if OOM)\n",
    "\n",
    "\n",
    "# --- 2. PERSIAN NORMALIZATION FUNCTION (CRITICAL FOR METRICS) ---\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Applies standard normalization rules for ASR metric comparison:\n",
    "    1. Unifies common Persian character variants (Kaf, Yeh).\n",
    "    2. Removes punctuation and multiple spaces.\n",
    "    \"\"\"\n",
    "    if not text: return \"\"\n",
    "    text = str(text).lower().strip()\n",
    "\n",
    "    # Unify ambiguous characters\n",
    "    text = text.replace('\u064a', '\u06cc').replace('\u0643', '\u06a9')\n",
    "\n",
    "    # Remove punctuation, symbols, and non-letter characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Handle zero-width non-joiner (ZWNJ) which can interfere with tokenization\n",
    "    text = text.replace('\\u200c', ' ')\n",
    "\n",
    "    # Consolidate and clean whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "# --- 3. LOAD MODEL, PROCESSOR, AND DATA ---\n",
    "print(f\"Loading model: {MODEL_ID} and running on {DEVICE}...\")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForCTC.from_pretrained(MODEL_ID).to(DEVICE)\n",
    "\n",
    "# Load the test dataset and cast to 16kHz audio format (required by HuBERT)\n",
    "raw_dataset = load_dataset(DATASET_ID, split=SPLIT)\n",
    "raw_dataset = raw_dataset.cast_column(\"audio\", Audio(sampling_rate=SAMPLING_RATE))\n",
    "\n",
    "# Load metrics\n",
    "wer_metric = load(\"wer\")\n",
    "cer_metric = load(\"cer\")\n",
    "\n",
    "\n",
    "# --- 4. DATA PREPROCESSING FUNCTION ---\n",
    "def prepare_dataset(batch):\n",
    "    # Process the audio array for the model\n",
    "    audio = batch[\"audio\"]\n",
    "    batch[\"input_features\"] = processor(\n",
    "        audio[\"array\"],\n",
    "        sampling_rate=audio[\"sampling_rate\"],\n",
    "        return_tensors=\"pt\"\n",
    "    ).input_values[0]\n",
    "\n",
    "    # Normalize and encode the target text (labels)\n",
    "    normalized_text = normalize_text(batch[\"sentence\"])\n",
    "    batch[\"labels\"] = processor.tokenizer(normalized_text).input_ids\n",
    "\n",
    "    return batch\n",
    "\n",
    "# Apply preprocessing\n",
    "processed_dataset = raw_dataset.map(\n",
    "    prepare_dataset,\n",
    "    remove_columns=raw_dataset.column_names,\n",
    "    num_proc=1 # Use 1 process to avoid multiprocessing issues with torchcodec\n",
    ")\n",
    "\n",
    "# --- 5. DATA COLLATOR (for batching padded sequences) ---\n",
    "def data_collator(features):\n",
    "    input_features = [{\"input_values\": feature[\"input_features\"]} for feature in features]\n",
    "    label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "    batch = processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "    # Pad labels manually\n",
    "    labels_batch = processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "    batch[\"labels\"] = labels_batch[\"input_ids\"]\n",
    "    return batch\n",
    "\n",
    "\n",
    "# --- 6. EVALUATION LOOP ---\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    processed_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "all_predictions = []\n",
    "all_references = []\n",
    "\n",
    "model.eval()\n",
    "print(f\"\\nStarting inference on {len(processed_dataset)} test samples...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        # Move tensors to the appropriate device (CPU/GPU)\n",
    "        input_values = batch[\"input_values\"].to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE)\n",
    "\n",
    "        # Forward pass to get logits (raw predictions)\n",
    "        logits = model(input_values).logits\n",
    "\n",
    "        # CTC Greedy Decoding\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        # Decode the predicted IDs to text\n",
    "        predictions_text = processor.batch_decode(predicted_ids)\n",
    "\n",
    "        # Decode the reference IDs back to text for comparison\n",
    "        # (This is safe because the labels were encoded using the same normalization)\n",
    "        labels_ids = np.where(labels.cpu().numpy() != -100, labels.cpu().numpy(), processor.tokenizer.pad_token_id)\n",
    "        references_text = processor.batch_decode(labels_ids, group_tokens=False)\n",
    "\n",
    "        # Store normalized results\n",
    "        all_predictions.extend([normalize_text(p) for p in predictions_text])\n",
    "        all_references.extend([normalize_text(r) for r in references_text])\n",
    "\n",
    "# --- 7. CALCULATE FINAL METRICS ---\n",
    "final_wer = wer_metric.compute(predictions=all_predictions, references=all_references)\n",
    "final_cer = cer_metric.compute(predictions=all_predictions, references=all_references)\n",
    "\n",
    "print(f\"\\n---------------------------------------------------------\")\n",
    "print(f\"ASR Model: {MODEL_ID}\")\n",
    "print(f\"Dataset: {DATASET_ID} | Split: {SPLIT} ({len(processed_dataset)} samples)\")\n",
    "print(f\"---------------------------------------------------------\")\n",
    "print(f\"Word Error Rate (WER):      {final_wer * 100:.2f}%\")\n",
    "print(f\"Character Error Rate (CER): {final_cer * 100:.2f}%\")\n",
    "print(f\"---------------------------------------------------------\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 916,
     "referenced_widgets": [
      "cb2ea0031b164f17981a66cba99b603d",
      "2aaf2061df6349c4a0bae5cefcc7f92d",
      "b32d89672f514e00805a76fec1978d81",
      "d7aca04611024a50881902ceca37e6f6",
      "de654609e0ac4119ad4b8ea2f5e7f7b7",
      "baf04b2ad46e4027a8f119efa0c300f8",
      "1f7aa84e06764d04a5567b3db224c1a9",
      "d7d4b8c557664f95b9b52df47882190c",
      "6afc5c0597254388872799137b9f04f8",
      "921c6f6f91c148f7bea335db4ccf1155",
      "4de5084b4d8441b797b7c664906d22c7",
      "a36b97aa16e14a6ea18f0c197253038f",
      "9635911b1c0c45c69c0e0a22305ecc06",
      "dbcf92475eaf47c0b8f5cc18a5f3600d",
      "0f83d4da5eba46c18b742255477ebd54",
      "bacd939142064acc99bb8b98b6478b6e",
      "d55cc577b890409e9086000cea227215",
      "3cf539b5276e4450b5ffc4851f2e7332",
      "aa50a5a92a5c4e7c90e4ccab0ce6c8c3",
      "a8b34b3e7fc34958a00b4e628a611a60",
      "7d08f526476048c0833111323c00c49c",
      "a229840875904089b2e8d492038991ab"
     ]
    },
    "id": "zj3pUSkJKSVK",
    "outputId": "e4baf337-e0c5-4700-e19d-68353fe2e20f"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Loading model: jonatasgrosman/exp_w2v2t_fa_hubert_s801 and running on cuda...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/10440 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb2ea0031b164f17981a66cba99b603d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Starting inference on 10440 test samples...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/1305 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a36b97aa16e14a6ea18f0c197253038f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "---------------------------------------------------------\n",
      "ASR Model: jonatasgrosman/exp_w2v2t_fa_hubert_s801\n",
      "Dataset: hezarai/common-voice-13-fa | Split: test (10440 samples)\n",
      "---------------------------------------------------------\n",
      "Word Error Rate (WER):      55.20%\n",
      "Character Error Rate (CER): 16.16%\n",
      "---------------------------------------------------------\n"
     ]
    }
   ]
  }
 ]
}
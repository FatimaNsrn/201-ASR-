{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TMVJWSd_36Rc",
    "outputId": "00325283-61d6-4235-aefd-f48052650ac3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Mount Drive to access your saved model\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6grX5XHz4NdA",
    "outputId": "dc49979f-e919-48c1-dd6a-6530e2e1f37c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint-3504  checkpoint-5256  runs\n"
     ]
    }
   ],
   "source": [
    "# Check your checkpoint exists\n",
    "!ls /content/drive/MyDrive/wav2vec2-persian/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "TzYPV1dE4Sq7",
    "outputId": "41ee94a1-d155-4fe4-a395-6ad020342d20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Collecting pyctcdecode\n",
      "  Downloading pyctcdecode-0.5.0-py2.py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: torch==2.9.0 in /usr/local/lib/python3.12/dist-packages (from torchaudio) (2.9.0+cu126)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (3.5.0)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pygtrie<3.0,>=2.1 (from pyctcdecode)\n",
      "  Downloading pygtrie-2.5.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting hypothesis<7,>=6.14 (from pyctcdecode)\n",
      "  Downloading hypothesis-6.148.7-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from hypothesis<7,>=6.14->pyctcdecode) (2.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.9.0->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.0->torchaudio) (3.0.3)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyctcdecode-0.5.0-py2.py3-none-any.whl (39 kB)\n",
      "Downloading hypothesis-6.148.7-py3-none-any.whl (538 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m538.1/538.1 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m127.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pygtrie-2.5.0-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: pygtrie, numpy, hypothesis, pyctcdecode, evaluate\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed evaluate-0.4.6 hypothesis-6.148.7 numpy-1.26.4 pyctcdecode-0.5.0 pygtrie-2.5.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "d60ada1c7a0c468eb870c9de3ffe6774",
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
      "  Downloading https://github.com/kpu/kenlm/archive/master.zip\n",
      "\u001b[2K     \u001b[32m-\u001b[0m \u001b[32m553.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m^C\n"
     ]
    }
   ],
   "source": [
    "# Install libraries\n",
    "!pip install transformers datasets evaluate torchaudio pyctcdecode\n",
    "!pip install https://github.com/kpu/kenlm/archive/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "wmtpYsIt4mId",
    "outputId": "93e84382-5ea8-40e7-df5e-f3d0f29518a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
      "  Using cached https://github.com/kpu/kenlm/archive/master.zip\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: kenlm\n",
      "  Building wheel for kenlm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for kenlm: filename=kenlm-0.2.0-cp312-cp312-linux_x86_64.whl size=3187999 sha256=105cb0044fdf784f82e1b474c209993902c6a5dded60adc731e7f5105dba3537\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4nvnnm1f/wheels/92/c8/12/56d187154e078f0eaa74d059017fc1afe1c4d91fbce02ce8d9\n",
      "Successfully built kenlm\n",
      "Installing collected packages: kenlm\n",
      "Successfully installed kenlm-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install https://github.com/kpu/kenlm/archive/master.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIvqAEbu44AH"
   },
   "outputs": [],
   "source": [
    "# Load everything\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6BkiBwa5DzN"
   },
   "outputs": [],
   "source": [
    "# Load model from your checkpoint\n",
    "model_name = \"m3hrdadfi/wav2vec2-large-xlsr-persian-v3\"\n",
    "checkpoint_path = \"/content/drive/MyDrive/wav2vec2-persian/checkpoint-5256\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A9cjh5gv5OBN",
    "outputId": "8ce5202a-96cd-4d1c-f8c9-e8301ea1a630"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py:335: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained(checkpoint_path)\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "model.eval()\n",
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rATJ8F7_5XK-"
   },
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "ds_test_raw = load_dataset(\"hezarai/common-voice-13-fa\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RtW8dRdi5f47"
   },
   "outputs": [],
   "source": [
    "# Download KenLM\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "lm_file = hf_hub_download(\n",
    "    repo_id=\"mlengineer-ai/kenlm-sp-jomleh\",\n",
    "    filename=\"files/jomleh-sp-32000-o3-prune011.probing\",  # 32K vocab, 3-gram\n",
    "    repo_type=\"model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "7c0gCts27zHr",
    "outputId": "8b539a1a-2483-4bea-ab62-2d1a81ab0ace"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyctcdecode in /usr/local/lib/python3.12/dist-packages (0.5.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.15.0 in /usr/local/lib/python3.12/dist-packages (from pyctcdecode) (1.26.4)\n",
      "Requirement already satisfied: pygtrie<3.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from pyctcdecode) (2.5.0)\n",
      "Requirement already satisfied: hypothesis<7,>=6.14 in /usr/local/lib/python3.12/dist-packages (from pyctcdecode) (6.148.7)\n",
      "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from hypothesis<7,>=6.14->pyctcdecode) (2.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyctcdecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q2wfEeDT5-BS",
    "outputId": "8f0d7378-3cee-4ff0-a0fa-d4e4e73922de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pyctcdecode.decoder:Unigrams not provided and cannot be automatically determined from LM file (only arpa format). Decoding accuracy might be reduced.\n",
      "WARNING:pyctcdecode.alphabet:Found entries of length > 1 in alphabet. This is unusual unless style is BPE, but the alphabet was not recognized as BPE type. Is this correct?\n",
      "WARNING:pyctcdecode.language_model:No known unigrams provided, decoding results might be a lot worse.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Everything loaded! Ready for inference with LM\n"
     ]
    }
   ],
   "source": [
    "# Build decoder\n",
    "from pyctcdecode import build_ctcdecoder\n",
    "\n",
    "vocab_dict = processor.tokenizer.get_vocab()\n",
    "sorted_vocab = sorted(vocab_dict.items(), key=lambda x: x[1])\n",
    "vocab_list = [x[0] for x in sorted_vocab]\n",
    "\n",
    "decoder = build_ctcdecoder(\n",
    "    labels=vocab_list,\n",
    "    kenlm_model_path=lm_file,\n",
    ")\n",
    "\n",
    "print(\"âœ… Everything loaded! Ready for inference with LM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qOwNooYF-rKU",
    "outputId": "779232fe-1419-40bd-e6a3-644f7ed6f60a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŸ¢ Testing WITH Language Model:\n",
      "\n",
      "Reference:  Ø§ØªÙˆØ¨ÙˆØ³ Ù…Ø³Ø§ÙØ±ÛŒ\n",
      "Prediction: Ø§ØªÙˆØ¨ÙˆØ³ Ù…Ø³Ø§ÙØ±ÛŒ\n",
      "\n",
      "Reference:  Ø§Ù†Ø¹Ú©Ø§Ø³ Ù…Ø«Ø¨Øª Ø¯Ù‡ÛŒØ¯ Ùˆ Ø§Ø¹ØªØ¨Ø§Ø± Ø¨Ø¨Ø®Ø´ÛŒØ¯\n",
      "Prediction: Ø§Ù†Ø¹Ú©Ø§Ø³ Ù…Ø«Ø¨Øª Ø¯Ù‡ÛŒØ¯ Ùˆ Ø§Ø¹ØªØ¨Ø§Ø± Ø¨Ø¨Ø®Ø´ÛŒØ¯â‡\n",
      "\n",
      "Reference:  Ø¬Ù†Ú¯ Ø§ÙØ²Ø§Ø±Ù‡Ø§ÛŒ Ø³Ø§Ø¯Ù‡\n",
      "Prediction: Ø¬Ù†Ú¯ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ø³Ø§Ø²Ù‡\n",
      "\n",
      "Reference:  Ø¢ÛŒØ§ Ø­Ø¶Ø±Øª Ø¹Ø§Ù„ÛŒ Ù…Ø±Ø§ ØµØ¯Ø§ Ø²Ø¯ÛŒØ¯ØŸ\n",
      "Prediction: Ø¢ÛŒØ§ Ø­Ø¶Ø±Øª Ø¹Ø§Ù„ÛŒ Ù…Ø±Ø§ØµØ¯Ø§Ø²Ø¯ÛŒØ¯â‡\n",
      "\n",
      "Reference:  Ø¨Ø§ÛŒØ¯ Ø¨Ø§Ù‡Ø§Ø´ Ø­Ø±Ù Ø¨Ø²Ù†Ù… -\n",
      "Prediction: Ø¨Ø§â‡Ø¯ Ø¨Ø§Ù‡Ø§Ø´ Ø­Ø±Ù Ø¨Ø²Ù†Ù…\n",
      "\n",
      "Reference:  ØºØ¯Ø¯ Ù„Ù†ÙØ§ÙˆÛŒ Ù…Ù† ÙˆØ±Ù… Ú©Ø±Ø¯Ù‡ Ø§Ù†Ø¯.\n",
      "Prediction: Ø¹Ø¯Ø¯ Ù„Ù†ÙØ§ÙˆÛŒÙ…Ù† ÙˆÛŒÙ…Ú©Ø§ÛŒØ¯Ù‡Ø§Ù†Ø¯â‡\n",
      "\n",
      "Reference:  ØªÙˆ Ø§ÛŒÙ† Ø¯Ù†ÛŒØ§ ÛŒÚ©ÛŒ Ø¯Ù„ÛŒÙ„ Ø²Ù†Ø¯Ú¯ÛŒÙ…Ù‡\n",
      "Prediction: ØªÙˆ Ø§ÛŒÙ† Ø¯Ù†ÛŒØ§â‡ÛŒÚ©ÛŒ Ø¯Ù„ÛŒÙ„ Ø²Ù†Ø¯Ú¯ÛŒÙ…Ù‡\n",
      "\n",
      "Reference:  Ù…Ù† Ø®ÛŒÙ„ÛŒ Ø¨Ù‡ØªÙˆÙ† Ø¹Ù„Ø§Ù‚Ù‡ Ø¯Ø§Ø±Ù… Ùˆ Ø§Ø²ØªÙˆÙ† Ù…ÛŒØ®ÙˆØ§Ù… Ú©Ù‡ Ø§Ú¯Ù‡ Ø´Ù…Ø§ Ù‡Ù… Ù…Ù†Ùˆ Ù…ÛŒÙ¾Ø³Ù†Ø¯ÛŒÙ† Ùˆ Ø¨Ù‡Ù… Ø¹Ù„Ø§Ù‚Ù‡ Ø¯Ø§Ø±ÛŒÙ† Ø¨ÛŒØ´ØªØ± Ø§Ø´Ù†Ø§ Ø¨Ø´ÛŒÙ…\n",
      "Prediction: Ù…Ù† Ø®ÛŒÙ„ÛŒ Ø¨Ù‡ØªÙˆÙ† Ø¹Ù„Ø§Ù‚Ù‡ Ø¯Ø§Ø±Ù…ÙˆØ§Ø²ØªÙˆÙ† Ù…ÛŒØ®ÙˆØ§Ù… Ú©Ù‡ Ø§Ú¯Ù‡ Ø´Ù…Ø§ Ù‡Ù… Ù…Ù†Ùˆ Ù…ÛŒ Ù¾Ø³Ù†Ø¯ÛŒ Ùˆ Ø¨Ù‡ Ù… Ø¹Ù„Ø§Ù‚Ù‡ Ø¯Ø§Ø±ÛŒÙ† Ø¨ÛŒØ´ØªØ± Ø¢Ø´Ù†Ø§ Ø¨Ø´ÛŒÙ…\n",
      "\n",
      "Reference:  Ùˆ Ø®ÛŒÙ„ÛŒÙ‡Ø§ Ù…Ø§Ø¯Ø± Ø´Ø¯Ù†Ø¯ ÙˆÙ‚ØªÛŒ Ø®ÙˆØ¯Ø´Ø§Ù† Ù‡Ù†ÙˆØ² Ø¨Ú†Ù‡ Ø¨ÙˆØ¯Ù†Ø¯\n",
      "Prediction: Ùˆ Ø®ÛŒÙ„ÛŒ Ù‡Ù…Ø§Ø¯Ù‡Ø§Ø³Ø¯Ù‚ØªÛŒÚ¯ÙØªØ§Ù† Ù‡Ù†ÙˆØ² Ø¨Øª Ø¯Ù†Ø¯\n",
      "\n",
      "Reference:  Ù…ÛŒ Ø®ÙˆØ§Ù… Ø¨Ú†Ù‡ Ø¯Ø§Ø± Ø¨Ø´Ù…\n",
      "Prediction: Ù…ÛŒØ®ÙˆØ§Ù… Ø¨Ú†Ù‡ Ø¯Ø§Ø± Ø¨Ø´Ù…â‡\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test inference with LM\n",
    "def transcribe_with_lm(audio_array):\n",
    "    inputs = processor(audio_array, sampling_rate=16000, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    # Decode with LM\n",
    "    beam_results = decoder.decode_beams(logits.cpu().numpy()[0])\n",
    "    transcription = beam_results[0][0]  # Best hypothesis\n",
    "\n",
    "    return transcription\n",
    "\n",
    "# Test on some examples\n",
    "print(\"ğŸŸ¢ Testing WITH Language Model:\\n\")\n",
    "\n",
    "for i in range(10):\n",
    "    audio = ds_test_raw[i][\"audio\"][\"array\"]\n",
    "    sampling_rate = ds_test_raw[i][\"audio\"][\"sampling_rate\"]\n",
    "    reference = ds_test_raw[i][\"sentence\"]\n",
    "\n",
    "    if sampling_rate != 16000:\n",
    "        audio = torchaudio.functional.resample(\n",
    "            torch.tensor(audio), sampling_rate, 16000\n",
    "        ).numpy()\n",
    "\n",
    "    prediction = transcribe_with_lm(audio)\n",
    "\n",
    "    print(f\"Reference:  {reference}\")\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257,
     "referenced_widgets": [
      "50a0b59f216a412a860396afd7dce7c7",
      "de73133c33de4b3da264eaeb3de37ece",
      "1d6189c0865f44c4a099739ad27c45ae",
      "630400cbd281445ea9785b11dfa85211",
      "806f52b4fa7948279b743b96a48de0e8",
      "d42713fdc0464041b6f6bb24dbdd47db",
      "270d896f963845e3960fe4d333d8abfa",
      "6337eb2833b94c9bb655d5e05486d426",
      "f50f1719e46742f6a5a21f7367d8acc3",
      "a02c12b680e04af2be6c02690de2e949",
      "c726fc31517b41138500f3354f08689e"
     ]
    },
    "id": "uLwGjn6v_pGS",
    "outputId": "3f81f1f1-cd1e-45d0-8189-d1f61f321f1b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a0b59f216a412a860396afd7dce7c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating with LM on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10440/10440 [16:50<00:00, 10.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ“Š RESULTS COMPARISON:\n",
      "==================================================\n",
      "WITHOUT LM - WER: 0.2749 | CER: 0.1452\n",
      "WITH LM    - WER: 0.4176 | CER: 0.1012\n",
      "==================================================\n",
      "\n",
      "âœ… WER Improvement: -51.9%\n",
      "âœ… CER Improvement: 30.3%\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load metrics\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "cer_metric = evaluate.load(\"cer\")\n",
    "\n",
    "# Evaluate with LM on full test set\n",
    "predictions_with_lm = []\n",
    "references = []\n",
    "\n",
    "print(\"Evaluating with LM on test set...\")\n",
    "\n",
    "for i in tqdm(range(len(ds_test_raw))):\n",
    "    audio = ds_test_raw[i][\"audio\"][\"array\"]\n",
    "    sampling_rate = ds_test_raw[i][\"audio\"][\"sampling_rate\"]\n",
    "    reference = ds_test_raw[i][\"sentence\"]\n",
    "\n",
    "    # Resample if needed\n",
    "    if sampling_rate != 16000:\n",
    "        audio = torchaudio.functional.resample(\n",
    "            torch.tensor(audio), sampling_rate, 16000\n",
    "        ).numpy()\n",
    "\n",
    "    # Transcribe with LM\n",
    "    inputs = processor(audio, sampling_rate=16000, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    beam_results = decoder.decode_beams(logits.cpu().numpy()[0])\n",
    "    prediction = beam_results[0][0]\n",
    "\n",
    "    predictions_with_lm.append(prediction)\n",
    "    references.append(reference)\n",
    "\n",
    "# Calculate metrics\n",
    "wer_with_lm = wer_metric.compute(predictions=predictions_with_lm, references=references)\n",
    "cer_with_lm = cer_metric.compute(predictions=predictions_with_lm, references=references)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ“Š RESULTS COMPARISON:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"WITHOUT LM - WER: 0.2749 | CER: 0.1452\")\n",
    "print(f\"WITH LM    - WER: {wer_with_lm:.4f} | CER: {cer_with_lm:.4f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Calculate improvement\n",
    "wer_improvement = (0.2749 - wer_with_lm) / 0.2749 * 100\n",
    "cer_improvement = (0.1452 - cer_with_lm) / 0.1452 * 100\n",
    "\n",
    "print(f\"\\nâœ… WER Improvement: {wer_improvement:.1f}%\")\n",
    "print(f\"âœ… CER Improvement: {cer_improvement:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uYoTXOzf_u_M",
    "outputId": "4013ffd4-046b-451a-9ac9-1f5360c7b769"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jiwer\n",
      "  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from jiwer) (8.3.1)\n",
      "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
      "  Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
      "Downloading jiwer-4.0.0-py3-none-any.whl (23 kB)\n",
      "Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
      "Successfully installed jiwer-4.0.0 rapidfuzz-3.14.3\n"
     ]
    }
   ],
   "source": [
    "!pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fw7D4Egd-wlp",
    "outputId": "4ac472e7-c3ae-4fd9-f43d-3f28776da53d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchcodec\n",
      "  Downloading torchcodec-0.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
      "Downloading torchcodec-0.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchcodec\n",
      "Successfully installed torchcodec-0.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchcodec"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TiYc6rcOSQxA",
    "outputId": "7cc5fac8-d2e7-49fd-f987-27c1e7cdc911"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting filelock (from transformers)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Downloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting packaging>=20.0 (from transformers)\n",
      "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests (from transformers)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers)\n",
      "  Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.2/507.2 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.4/159.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.5/153.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.2/131.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3, typing-extensions, tqdm, safetensors, regex, pyyaml, packaging, numpy, idna, hf-xet, fsspec, filelock, charset_normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.5.0\n",
      "    Uninstalling urllib3-2.5.0:\n",
      "      Successfully uninstalled urllib3-2.5.0\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.15.0\n",
      "    Uninstalling typing_extensions-4.15.0:\n",
      "      Successfully uninstalled typing_extensions-4.15.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.67.1\n",
      "    Uninstalling tqdm-4.67.1:\n",
      "      Successfully uninstalled tqdm-4.67.1\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.7.0\n",
      "    Uninstalling safetensors-0.7.0:\n",
      "      Successfully uninstalled safetensors-0.7.0\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2025.11.3\n",
      "    Uninstalling regex-2025.11.3:\n",
      "      Successfully uninstalled regex-2025.11.3\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0.3\n",
      "    Uninstalling PyYAML-6.0.3:\n",
      "      Successfully uninstalled PyYAML-6.0.3\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.11\n",
      "    Uninstalling idna-3.11:\n",
      "      Successfully uninstalled idna-3.11\n",
      "  Attempting uninstall: hf-xet\n",
      "    Found existing installation: hf-xet 1.2.0\n",
      "    Uninstalling hf-xet-1.2.0:\n",
      "      Successfully uninstalled hf-xet-1.2.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.0\n",
      "    Uninstalling fsspec-2025.3.0:\n",
      "      Successfully uninstalled fsspec-2025.3.0\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.20.0\n",
      "    Uninstalling filelock-3.20.0:\n",
      "      Successfully uninstalled filelock-3.20.0\n",
      "  Attempting uninstall: charset_normalizer\n",
      "    Found existing installation: charset-normalizer 3.4.4\n",
      "    Uninstalling charset-normalizer-3.4.4:\n",
      "      Successfully uninstalled charset-normalizer-3.4.4\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2025.11.12\n",
      "    Uninstalling certifi-2025.11.12:\n",
      "      Successfully uninstalled certifi-2025.11.12\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.4\n",
      "    Uninstalling requests-2.32.4:\n",
      "      Successfully uninstalled requests-2.32.4\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.36.0\n",
      "    Uninstalling huggingface-hub-0.36.0:\n",
      "      Successfully uninstalled huggingface-hub-0.36.0\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.22.1\n",
      "    Uninstalling tokenizers-0.22.1:\n",
      "      Successfully uninstalled tokenizers-0.22.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.57.3\n",
      "    Uninstalling transformers-4.57.3:\n",
      "      Successfully uninstalled transformers-4.57.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.12.0 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
      "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.12.0 which is incompatible.\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.5 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed certifi-2025.11.12 charset_normalizer-3.4.4 filelock-3.20.0 fsspec-2025.12.0 hf-xet-1.2.0 huggingface-hub-0.36.0 idna-3.11 numpy-2.3.5 packaging-25.0 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 safetensors-0.7.0 tokenizers-0.22.1 tqdm-4.67.1 transformers-4.57.3 typing-extensions-4.15.0 urllib3-2.6.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "0430efb386a443b99ecf4c3d2ad2665a",
       "pip_warning": {
        "packages": [
         "certifi",
         "numpy",
         "packaging"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install --upgrade --force-reinstall transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "cv401P4TSqrQ",
    "outputId": "bd2679d6-4188-4e6a-9003-b79bc769ba10"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'4.57.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5JRvSTjQSwl4",
    "outputId": "b86a9a62-81b7-4d0f-fd9a-1bfe1c545342"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchcodec\n",
      "  Downloading torchcodec-0.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
      "Downloading torchcodec-0.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (2.1 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/2.1 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchcodec\n",
      "Successfully installed torchcodec-0.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchcodec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A64NRqX8S3R6",
    "outputId": "b56f57d1-95c2-4295-dde9-a4a30301dc14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.3.5)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.11.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fsspec, evaluate\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.12.0\n",
      "    Uninstalling fsspec-2025.12.0:\n",
      "      Successfully uninstalled fsspec-2025.12.0\n",
      "Successfully installed evaluate-0.4.6 fsspec-2025.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HODBcrAnTBHf",
    "outputId": "1271c7bb-bdba-4b47-8ae9-7c9bdc4c47d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 769,
     "referenced_widgets": [
      "242bbbb9392740d8a3de6216ccbb01ad",
      "d41459c897cd4322a44f48ad40724e18",
      "34811b0a84a64166863cedffc6cf7dd3",
      "9d9e6b22ff9b474f8d3ee004122f21c9",
      "6554fc631427438b88b204126255e7ea",
      "300427dce9014806a5517be3469350e8",
      "11eae1d15b2644d4aa3b43fa49d2a0b4",
      "65978a59c7444cf48215f47e2f405361",
      "f09ee44664564ecf95b6b7e3c8da596d",
      "d499d4431d3e4f49b4d1420ab0658421",
      "f21ddbd6aca54fdbb6e6b1add524ab8c",
      "9852279779b345849c8d2be2f0650d1d",
      "569327d3c9d04b14ae0c7aacb438418d",
      "5c9e7df68c0f4a4d9f42512ccb87251e",
      "05a3d2aee07144a98b4de620ce238ea5",
      "ae87eb5752234968abbd0896c5b7730e",
      "8fc957ba8e5641daa1096eadb0a6eb80",
      "2d3c5c7c0eb64729b070cc77b852ef33",
      "eb3aa4a5438a4f6db9f5f28df5db963f",
      "6ba2337d6195453dbc9d4628ffff7833",
      "243f73a96ea9446e8a34defa45f690aa",
      "465084da5cac43749e4508d13125b58d",
      "47d188ab9ff64739b17329607d904136",
      "1e0f3b6424f14f548af10e3a8237ccda",
      "ee015cd5572541ae9ab3020cafcfc1ed",
      "50067f8ce27e47abb072ba3fa2c6a24e",
      "fbd64b84be5d4500b0bcbc61700182a4",
      "7a895a685a7e418b9f78bcfec0f18797",
      "d3300997e2b740aa8c66ce45653d6a6a",
      "789020aafa484b208ea0c13c3474d299",
      "fdfc07eb477d48448afa89b00cacfab0",
      "7bc491c3b95a4fb2b7f2d2dea74fa5a8",
      "081e81b9f14f4aec9a6683e406a71372",
      "471f87244a214ecca3b6052f6da53df3",
      "f1d44eee09ce4fea9ef23c3d1ae8dac7",
      "c6987b0f56454015b1ecbeb3547384d4",
      "3af7af36dd11461f824f62ba3f34eb5e",
      "74030812a0f2457783fcb7aed63ff3c0",
      "4040c39f9e924dacabe5326a7522e668",
      "aeef296a376f435faa685884aab5ab0b",
      "f94a5fd81b6a4b0d88a120665a9070fb",
      "afb9aac637de479d882422bbf646a381",
      "6f51db3eb519434e8c31d25a4ddf2b9e",
      "335153aa321b4436b0aee74cc0b4282d",
      "f466b871897a4ce7bab3465ae7d1fe6f",
      "d1e0976b5271408f853289764f7ba7d7",
      "e7ebdba5b20e4abd90d20c337176cb63",
      "1a5837a85d7d4855baa3c5ae5c78460c",
      "ea6383f7f46f48cab68baea05171560b",
      "03de141de9d9449daeede6388e3572d9",
      "51f889be0d8b41dc8303db1f8c5652e0",
      "df9bd2ac67564869ba35b94b15636d11",
      "a4a19437a25b41a3a3bfeca198799f5d",
      "fa365bd5ca66449793db90bf56194078",
      "a5ba795fd63c494f991b4ec3f6da5453",
      "42f28482b6ba456b9b0ac54eac107989",
      "3b92068368274cd6a2ff175099018297",
      "25d77d7c6ae3418cbc6bab9d46ff75cd",
      "1a77b998788649479501726484602f23",
      "a2614ef507784bcab8e040600a34882c",
      "69783d1633e84bd59de1239300446f09",
      "fba6e669317a4a0b92c46252d67d28f1",
      "507ab4c4c082418aa5c835ac34730424",
      "e836a457f33a41c190503cf720d90283",
      "354298732f654ab98b1fb6722abcbd27",
      "319c757f78274b19868b31acc51f144b",
      "e30ffa5ebf6647349a67aa056738ad5d",
      "26ed921f7dcf4f17a50a50849e7971df",
      "7ad255e0abc34917813134e91f32fb6a",
      "e2bbd390355a491dbe6822a54199506c",
      "9d195ab2ef814e9e8ec0a724fcd34b0d",
      "db9cae81b22540eab12a96bfcf359806",
      "9aebf499a0cd40259a54a61ed87c457b",
      "2913eb806ccb4a0fa9230b1ffd5b8832",
      "dc934c8df55b42e6b2d44d52661abf48",
      "d80723cb42df41d99ba0f3ee417a1e68",
      "e493136a047d4c57a91bc4cddac8a2c3",
      "5f9b346ba8814c00bc1953f1f70c1bdb",
      "2a748c939f414b96a455eac65dc2155a",
      "55086ee94203445cb2a273bf016448f4",
      "462a741e048f475e91d72989d9bb3987",
      "0767116447554df98d5622379e7f5641",
      "b8dc518c2b0c4b75b44d53d34623039e",
      "2a9260866d7e4db88ded2f8d80cde86c",
      "ad0b069f687140de90219d8e12f060f4",
      "f1cf8f1a1a064717a1a03868ee612a68",
      "ff003ed1538f4c12b051701a1113e5f9",
      "af83df16ffa94fa5b8d9238e8444b900"
     ]
    },
    "id": "ZLbI51O4TmsM",
    "outputId": "39541c56-deff-4d08-dc40-9c84086b6b14"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242bbbb9392740d8a3de6216ccbb01ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9852279779b345849c8d2be2f0650d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00002.parquet:   0%|          | 0.00/328M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d188ab9ff64739b17329607d904136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00001-of-00002.parquet:   0%|          | 0.00/329M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "471f87244a214ecca3b6052f6da53df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/validation-00000-of-00001.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f466b871897a4ce7bab3465ae7d1fe6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/383M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f28482b6ba456b9b0ac54eac107989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/28024 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e30ffa5ebf6647349a67aa056738ad5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10440 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9b346ba8814c00bc1953f1f70c1bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10440 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
      "        num_rows: 28024\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
      "        num_rows: 10440\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
      "        num_rows: 10440\n",
      "    })\n",
      "})\n",
      "{'client_id': 'f07716fdbad07f44e58a9597e164df11e5d8bbe99a8f3ec384f6654d0f91aa55f0603e14b2c3c7f20f37da41784b20587a08f20cb6c434effff9904a5977e72f', 'path': '/fa_train_0/common_voice_fa_30206469.mp3', 'audio': <datasets.features._torchcodec.AudioDecoder object at 0x7cb3d9eeb5c0>, 'sentence': 'تا حرف پول به میان میآید گوشهایش را تیز میکند.', 'up_votes': 2, 'down_votes': 0, 'age': '', 'gender': '', 'accent': '', 'locale': 'fa', 'segment': '', 'variant': ''}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"hezarai/common-voice-13-fa\")\n",
    "print(ds)\n",
    "print(ds[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264,
     "referenced_widgets": [
      "cfb4ed70a60849ca9d07ba5a5a6c3cbf",
      "e3ea4c792030454ab05d7d5b80bfe670",
      "1b7fcbcb67af42faa2c6870b047d02e0",
      "4e206fda7eb54b7085d4fe89e7a8a3bb",
      "4526eac386bf4b8386751e99c5cc3f3b",
      "3cdf8b70f37149188328446d39f9290b",
      "4043318b46a64aeca61c95ad74431256",
      "308a8af1efad4dbf93774c47224a7721",
      "ec4cbe1765c04453944f7c22256dc8e9",
      "ec296544f20445bb981b1c8ef9623241",
      "39edbc1f4dbd4d6fb04b6284ae20e313",
      "20864c0f31754b12b9a4f62a2bd3e42a",
      "9577c4be7eaa492b91b4dc45e2511183",
      "5d37b4060f6e466a8eec7e32bbdca0c8",
      "3ca61be195f34f40bdfe6ab15cb7c61e",
      "08bf0cc59f5d456d971a4fbc5998395c",
      "37af43b24c624a4185ad06eebde4e4c9",
      "28dc4b41090c4eeb82a3a9ab05c006af",
      "9381801d552b4f2fb1ac8bb2780727dd",
      "40c90eaead5a4cc8ade4a87e33b95756",
      "045da18e6f974de9977f004754a43a5b",
      "9062109b2f904b82924263a274a13033",
      "e1640371e0314222bbd43320dd7d02e0",
      "84c17353646341f6befd0abddb81b72e",
      "dbd5009422954c7da69a9711aea446e4",
      "d5da510d8c3343929568404dcddf9435",
      "0eb3fd8fd80c449c9edfcf6fd6307953",
      "3af8d8e5d4724f5e9218b758ac850d73",
      "afcf6cbf92e9478b8b91dba20d394603",
      "e4b8fa79fa4740f99f185417441b72df",
      "1072c7fe587841e89d52645d8596c25c",
      "732b1bc1290b41f0b82d20b13049e36c",
      "6434ec5c69ca4ec9ae2001fc78da4c32",
      "59935daa36d44bc7bc70fe5114be0284",
      "4716ce4f0a154b7c83bf886ce7752523",
      "76c4c8e3848b4793a174f273b6d112fd",
      "496f0128727d452a9ef441eba1f4b4c7",
      "cc14c29d14644b96bfe9b2dd6a3b4c55",
      "3b5850abf1bc4617905bc2ddeb5d0d2e",
      "7f886a667b164292bd9d0a43a5ea3caa",
      "54ed51fcad364b0a84a376d20f401bbc",
      "08ee298bc15a4d1eb2fbbfe02df77639",
      "65e6f095aeaf423c823ea2eea16ba6c2",
      "c3a8baf9e631425f8149a53906d69081",
      "2792732df5034c6aadffd262ce32f1f6",
      "9cbfa42e5cb34431a4472308c999317c",
      "8353a224eb76419a8c8c96000819d518",
      "8270acb7d0ef4b71af80835c300c3cb4",
      "bb110bc7699c48fb9e646b174e305c47",
      "79870876f53741a197e5877d68549b0a",
      "8a2ececfb04148fb8f3b51d6625ccaf8",
      "d90681d4f29a439cbde8557f07e30034",
      "c6eef3ad9cb2406c9c4e7ebc02dbddb8",
      "90ee40ba5a2a4e2180bd07d92f85aa1d",
      "1f28619cbe514cf1a115889315e57337",
      "44f56652bec5481f90a755689e492cd3",
      "0ef5b083f83e41e299612971330d153c",
      "67086ddc130d4a979b0e84f02d7e86f3",
      "5279baa625a44b379bf860d36cab52ca",
      "11f9b2073c744931871a8ac40c93fdf2",
      "7c69709ef67b4e89a1f079a86834f794",
      "c600ffac09a34b6bbb601d4e9cb01d84",
      "b727280a48d447faabb9f728140cbccb",
      "81e3e28f78304abf86be48fc889feaf8",
      "4c3202fe6d274f43a38376ee1b3eed85",
      "8805b027f78f44589b3830d9925c0202"
     ]
    },
    "id": "k3vXwahWT0kv",
    "outputId": "6f0fa32d-0791-4a9f-bc80-2cbcb2937cbe"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb4ed70a60849ca9d07ba5a5a6c3cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/214 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20864c0f31754b12b9a4f62a2bd3e42a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/307 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1640371e0314222bbd43320dd7d02e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py:335: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59935daa36d44bc7bc70fe5114be0284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/399 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2792732df5034c6aadffd262ce32f1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f56652bec5481f90a755689e492cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.26G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "\n",
    "model_name = \"m3hrdadfi/wav2vec2-large-xlsr-persian-v3\"\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zhUm9ObPUG7v"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    \"\"\"\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        labels_batch = self.processor.tokenizer.pad(\n",
    "            label_features,\n",
    "            padding=self.padding,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_4SyTQzNULBn"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "def speech_file_to_array(batch):\n",
    "    speech_array, sampling_rate = batch[\"audio\"][\"array\"], batch[\"audio\"][\"sampling_rate\"]\n",
    "\n",
    "    if sampling_rate != 16000:\n",
    "        speech_array = torchaudio.functional.resample(\n",
    "            torch.tensor(speech_array),\n",
    "            sampling_rate,\n",
    "            16000\n",
    "        ).numpy()\n",
    "\n",
    "    batch[\"speech\"] = speech_array\n",
    "    batch[\"text\"] = batch[\"sentence\"]\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "84ac4179492949eab1f843faa042fd49",
      "6ad394ff484d475b9fd227857a068d8a",
      "3ff6ed9dced24332952ce4998901beb6",
      "cefeaa5e347b409fb435733746df1ee4",
      "5ea001530207411ba0a1459b4019449c",
      "790017e538584244a547fa63037eccf3",
      "1ad976d0405c4cb29ff711146d537f01",
      "2138d06ab67644409b71f8697ef69a9a",
      "3f6b19f791e94616a55aca8676595abc",
      "0dee2f0dc4e24e1d9b7f0c27ff52ce03",
      "eb077452db984023aafe2adba9678e02",
      "34d6480e2725477ba14a0d0d000a59fe",
      "8ff611e1382f445c88243598e01c719b",
      "6e5e29a129e9475997ce15b9cd187318",
      "8530c96e538a465ab2f0ab7b6b75e1a2",
      "1b3fe6d9a11e44c38b1ca38297647902",
      "072d69a5db314945b7a82ced7bd5f5a7",
      "b7713212581843cdb788c2e39e911d0c",
      "fbb7bcdf66ab47ebafbf286a53fecc80",
      "e39d62609c014194a00ee6fb9336234f",
      "840602012972428d964fc930eb1d9466",
      "cdbc5d74c41a458780dee4ef07c2ec45",
      "f16d197b2b544137a3c7dc5e705d53de",
      "f44317eecd0c47e0ba579e16e4d810fb",
      "0eeea2bdb70d49a7b812712c3ddc0316",
      "aca0cb58b1c8473d967283b19d68b2ff",
      "637be421658a4f6e9e48a8174db1b285",
      "8ba2aa7b4c1148848ef6f9606be1f8c0",
      "7a6a5ee21c244fcea97fb5c2f80dfced",
      "6e520e9d1e32433daa88933f07753914",
      "e5e02f346e084eb4a4f8bddb051a241d",
      "53dcf8d1c43446778bf257cfedb1cf52",
      "9582de4c32ec45609d1742ba47570667"
     ]
    },
    "id": "SaJoN_nXUPnF",
    "outputId": "69443047-671b-4316-af83-8b92f142b60d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ac4179492949eab1f843faa042fd49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/28024 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d6480e2725477ba14a0d0d000a59fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/10440 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16d197b2b544137a3c7dc5e705d53de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/10440 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = ds.map(speech_file_to_array, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "44c412a206f74789b2b0962a5bc256f3",
      "823e2f3380844d46b550dc2da257f33b",
      "7898027f7fbf49ddb37315f53b8e469e",
      "f1dba55a980c4f9ba4b3843dd4e73374",
      "c3fafaeccead44f5880f18b6049d4ac2",
      "054d13a9c19a40e591d6adff796a995f",
      "adbeda0a74b7468ea8f112d79ae62f21",
      "41b7571f983745dca2a1ec4446fa5152",
      "63e8b94d33fb41b796ac0346783f7358",
      "27504365683e42b49e885873034e1fbc",
      "d5f96cfe99d94c26b1da1743b41a5c3a",
      "86af1137a0e84e899d46ea7f9ece0e00",
      "ee8eb3ff75d448028acc244b7113cddc",
      "3d07717bca584a7ead02a692c1c31f10",
      "ed12aa3af33f42e7b75e8064d422b635",
      "394ed48f6d3c4c82aee7e5afdae3bec4",
      "5ebef9311b154cb5844b2b592ea7f3b6",
      "efa7c1c52b3d4209900348ad041f8211",
      "23cb1049c1e742feaca8b403e0e19cee",
      "5072d07acc6a4aafb8c1411252e57ad2",
      "78aaed12f88748b5a81015e778e6941a",
      "6f3409250a8047dd966e43376a8fa90d",
      "69a346da69624718b6d1fb21789e6e4d",
      "3effc87863ba42e0bce59dc66a92526e",
      "6981e2093b7c405586dfb077b5b0d195",
      "f981c8fe88bc41419d06455b2546bee5",
      "6ead246752da4c9793fe13b523f45011",
      "feb55fc83b444cf294cbfa567b703a60",
      "94e4ae6db19d4b05a429e9f593a6dedb",
      "d9852c138a3b4311a3f501c0dedf40f9",
      "ebdf47915f10487f9c480a2cf332b7ee",
      "4329b31088404094a0269a176c1a5136",
      "ea4748924a88419397c12c7e98000650"
     ]
    },
    "id": "BwNkozmXXA4Q",
    "outputId": "c92dd60d-0604-4702-f26f-db7e4dfa1834"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c412a206f74789b2b0962a5bc256f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/28024 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86af1137a0e84e899d46ea7f9ece0e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/10440 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a346da69624718b6d1fb21789e6e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/10440 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # tokenize text\n",
    "    batch[\"labels\"] = processor.tokenizer(batch[\"text\"]).input_ids\n",
    "\n",
    "    # normalize audio + padding later in DataCollator\n",
    "    batch[\"input_values\"] = processor(\n",
    "        batch[\"speech\"],\n",
    "        sampling_rate=16000,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=False\n",
    "    ).input_values[0]\n",
    "\n",
    "    return batch\n",
    "\n",
    "ds = ds.map(prepare_dataset, remove_columns=ds[\"train\"].column_names, num_proc=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RaT55WEKeuSc",
    "outputId": "870363ce-6d4d-42f3-8e01-43690fa97a92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jiwer\n",
      "  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from jiwer) (8.3.1)\n",
      "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
      "  Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
      "Downloading jiwer-4.0.0-py3-none-any.whl (23 kB)\n",
      "Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
      "Successfully installed jiwer-4.0.0 rapidfuzz-3.14.3\n"
     ]
    }
   ],
   "source": [
    "!pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "529bf68a10ed4bb191d8671d0c3d2bb2",
      "902e5fa8f12147d586f00119e7927f17",
      "aab2d61b20404db182a643d65ce12540",
      "0eeb713d09f24a1c883373c6301b17d6",
      "bac0f7f65b9140a493dac8aea14cc216",
      "8c9747e39ae940e3831a7b9646603f00",
      "e5753ed166924e4eb1934fc3dfae1adb",
      "116ef396a668449eaf16a7e3f90bebdb",
      "1330cf89c0e54003b4d17a7c93028f8e",
      "369e51f5b49545fdb052ac352020ce73",
      "f4f4c8e443e24ce99b6a578edd49cb80",
      "45b3421451e844818663662ec0b9a448",
      "b97089143ec24099a36f39352bdaffd3",
      "1afcde296c414b92ba9849355424bff9",
      "673139045b1f41888960873075cc7244",
      "7850ca322f314a93b02319a1d5610c26",
      "451470fae3224dc38bb0cfd47467bd56",
      "72cfa95a57f445778adf62d2b57daf54",
      "11bc1dfa70bd4932ac4bed3c7bc09be5",
      "afc1ebe9270242e1a8c8c440f3294e32",
      "d33a5e7aa1254704ad5f49de3fec5703",
      "d0341cf8c22b42aa9c4ca8009b51d278"
     ]
    },
    "id": "uJCxC4-8ey4V",
    "outputId": "f2533bd4-0084-479e-e403-eb4534890855"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529bf68a10ed4bb191d8671d0c3d2bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b3421451e844818663662ec0b9a448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "cer_metric = evaluate.load(\"cer\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = pred_logits.argmax(-1)\n",
    "\n",
    "    # decode predictions\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "\n",
    "    # decode labels\n",
    "    label_ids = pred.label_ids\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    label_str = processor.batch_decode(label_ids, group_tokens=False)\n",
    "\n",
    "    # compute metrics\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer, \"cer\": cer}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "FfPQqiNPe-nv"
   },
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/wav2vec2-persian\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"loss\",\n",
    "    greater_is_better=False,\n",
    "    learning_rate=3e-4,\n",
    "    warmup_steps=500,\n",
    "    logging_steps=50,\n",
    "    num_train_epochs=3,\n",
    "    group_by_length=False,\n",
    "    fp16=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3SGEuFZ8fRx_"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "AA3ygmU8fVoF",
    "outputId": "d80c9e2f-ac44-4abb-f51d-90708266f2e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>/content/wandb/offline-run-20251211_173857-y25o2ibq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/backends/cudnn/__init__.py:145: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  torch._C._get_cudnn_allow_tf32(),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5256' max='5256' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5256/5256 3:32:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "      <th>Cer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.344500</td>\n",
       "      <td>0.290051</td>\n",
       "      <td>0.293538</td>\n",
       "      <td>0.126184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.253600</td>\n",
       "      <td>0.229945</td>\n",
       "      <td>0.246517</td>\n",
       "      <td>0.107262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.165600</td>\n",
       "      <td>0.214544</td>\n",
       "      <td>0.222065</td>\n",
       "      <td>0.101093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5256, training_loss=0.28631877109884674, metrics={'train_runtime': 12820.111, 'train_samples_per_second': 6.558, 'train_steps_per_second': 0.41, 'total_flos': 1.4846691340661023e+19, 'train_loss': 0.28631877109884674, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "-7Ddb7ZvQtqS",
    "outputId": "09361574-cf86-4961-80ab-0712d058e555"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1305' max='1305' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1305/1305 13:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results (without LM):\n",
      "WER: 0.2749\n",
      "CER: 0.1452\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_results = trainer.evaluate(ds[\"test\"])\n",
    "print(\"Test Results (without LM):\")\n",
    "print(f\"WER: {test_results['eval_wer']:.4f}\")\n",
    "print(f\"CER: {test_results['eval_cer']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zKVigjggV61o",
    "outputId": "e232987f-0264-4407-da52-874a73b432ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔴 Examples of WRONG predictions:\n",
      "\n",
      "Reference:  انعکاس مثبت دهید و اعتبار ببخشید\n",
      "Prediction: انعکاس مثبت دهید و اعتبا ببخشید<unk>\n",
      "\n",
      "Reference:  جنگ افزارهای ساده\n",
      "Prediction: جنگابزارهای ساده\n",
      "\n",
      "Reference:  آیا حضرت عالی مرا صدا زدید؟\n",
      "Prediction: آیا حدرت عالی مرا صدا زدید<unk>\n",
      "\n",
      "Reference:  باید باهاش حرف بزنم -\n",
      "Prediction: با<unk>د باهاش حرف بزنم\n",
      "\n",
      "Reference:  غدد لنفاوی من ورم کرده اند.\n",
      "Prediction: حدد لنفاوی من ویم کایدهاند<unk>\n",
      "\n",
      "Reference:  من خیلی بهتون علاقه دارم و ازتون میخوام که اگه شما هم منو میپسندین و بهم علاقه دارین بیشتر اشنا بشیم\n",
      "Prediction: من خیلی بهتون علاقه دارم و ازتون میخوام که اگه شما هم منو میپسندی و بهم علاقه دارین بیشتر آشنا بشیم\n",
      "\n",
      "Reference:  و خیلیها مادر شدند وقتی خودشان هنوز بچه بودند\n",
      "Prediction: و خیلی هماده اسدقتی گفتان هنوز بتو بدند\n",
      "\n",
      "Reference:  می خوام بچه دار بشم\n",
      "Prediction: می خوام بچه دار بشم<unk>\n",
      "\n",
      "Reference:  حال، مدیرعامل فودهولز، جان مککی و هیات مدیره نمیخواستند خود را به آمازون بفروشند\n",
      "Prediction: حال مدیرعامل فودهولز جان مکی و هیات مدیره نمیخواستند خود را به آمازون بفروشند<unk>\n",
      "\n",
      "Reference:  که کاگب تخم آنها را کاشت و هنوز هم میوه میدهد،\n",
      "Prediction: چه کاگبت خم آنها را کاشت و هنوز هم میوه میدهند<unk>\n",
      "\n",
      "Reference:  افراد مبتلا به دیابت، کسانی که امراض دیگر دارند، در خطر هستند\n",
      "Prediction: افراد مبتلا به دیابت کسن کهیاز دیگردارنه در خطر است\n",
      "\n",
      "Reference:  علاقه ای ندارم.\n",
      "Prediction: علاقهای ندارم<unk>\n",
      "\n",
      "Reference:  انگشتش رو بهم نشون داد\n",
      "Prediction: انگشتش رو بهم نشون داد<unk>\n",
      "\n",
      "Reference:  با آن ترکیب عالی از الگوریتم و خرد مردمی، توانستیم یک حلقه بازخورد فوری را ایجاد کنیم.\n",
      "Prediction: با آن تعرکیب عالی از الگوریتم و خرد مردم میتوانستیم یک طلقهی بازخورده فوری را ایجاد کنیم<unk>\n",
      "\n",
      "Reference:  تو خیلی باهوش و بانمکی\n",
      "Prediction: تو خیلی بعشوبانمکی\n",
      "\n",
      "Reference:  من و گروه همراه تصمیم به بررسی این مورد گرفتیم\n",
      "Prediction: من و هروه همراه تصمیم به وررستی این مورد گرفتیم\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Put model in eval mode and ensure correct dtype\n",
    "model.eval()\n",
    "model = model.to(\"cuda\")  # Make sure it's on GPU\n",
    "\n",
    "print(\"🔴 Examples of WRONG predictions:\\n\")\n",
    "\n",
    "for i in range(20):\n",
    "    # Get raw audio\n",
    "    audio_array = ds_test_raw[i][\"audio\"][\"array\"]\n",
    "    sampling_rate = ds_test_raw[i][\"audio\"][\"sampling_rate\"]\n",
    "    reference = ds_test_raw[i][\"sentence\"]\n",
    "\n",
    "    # Resample if needed\n",
    "    if sampling_rate != 16000:\n",
    "        import torchaudio\n",
    "        audio_array = torchaudio.functional.resample(\n",
    "            torch.tensor(audio_array),\n",
    "            sampling_rate,\n",
    "            16000\n",
    "        ).numpy()\n",
    "\n",
    "    # Transcribe - add .to(\"cuda\")\n",
    "    inputs = processor(audio_array, sampling_rate=16000, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}  # Move to GPU\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    prediction = processor.batch_decode(predicted_ids)[0]\n",
    "\n",
    "    # Show only if wrong\n",
    "    if prediction.strip() != reference.strip():\n",
    "        print(f\"Reference:  {reference}\")\n",
    "        print(f\"Prediction: {prediction}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 879
    },
    "id": "tJALaSILY7sO",
    "outputId": "e42c6a2f-61bd-4362-d13b-2a1a14b99aa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyctcdecode\n",
      "  Downloading pyctcdecode-0.5.0-py2.py3-none-any.whl.metadata (20 kB)\n",
      "Collecting numpy<2.0.0,>=1.15.0 (from pyctcdecode)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pygtrie<3.0,>=2.1 (from pyctcdecode)\n",
      "  Downloading pygtrie-2.5.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting hypothesis<7,>=6.14 (from pyctcdecode)\n",
      "  Downloading hypothesis-6.148.7-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from hypothesis<7,>=6.14->pyctcdecode) (2.4.0)\n",
      "Downloading pyctcdecode-0.5.0-py2.py3-none-any.whl (39 kB)\n",
      "Downloading hypothesis-6.148.7-py3-none-any.whl (538 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m538.1/538.1 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pygtrie-2.5.0-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: pygtrie, numpy, hypothesis, pyctcdecode\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.3.5\n",
      "    Uninstalling numpy-2.3.5:\n",
      "      Successfully uninstalled numpy-2.3.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
      "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed hypothesis-6.148.7 numpy-1.26.4 pyctcdecode-0.5.0 pygtrie-2.5.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "24600912de97491f9bb6e608ca327bc1",
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
      "  Downloading https://github.com/kpu/kenlm/archive/master.zip (553 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m553.6/553.6 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: kenlm\n",
      "  Building wheel for kenlm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for kenlm: filename=kenlm-0.2.0-cp312-cp312-linux_x86_64.whl size=3188000 sha256=0fb2be30f673c415f82e19e43c9a50310e07c93dd0dfc46ee4cd41646fb95c22\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-b1iq61jd/wheels/92/c8/12/56d187154e078f0eaa74d059017fc1afe1c4d91fbce02ce8d9\n",
      "Successfully built kenlm\n",
      "Installing collected packages: kenlm\n",
      "Successfully installed kenlm-0.2.0\n"
     ]
    }
   ],
   "source": [
    "# Install libraries\n",
    "!pip install pyctcdecode\n",
    "!pip install https://github.com/kpu/kenlm/archive/master.zip\n",
    "\n",
    "from pyctcdecode import build_ctcdecoder\n",
    "\n",
    "# Get your vocabulary from YOUR processor\n",
    "vocab_dict = processor.tokenizer.get_vocab()\n",
    "sorted_vocab = sorted(vocab_dict.items(), key=lambda x: x[1])\n",
    "vocab_list = [x[0] for x in sorted_vocab]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
